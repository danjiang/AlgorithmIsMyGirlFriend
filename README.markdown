## ⏳ 复杂度分析

### 时间复杂度分析

大 O 时间复杂度实际上并不具体表示代码真正的执行时间，而是表示代码执行时间随数据规模增长的变化趋势，所以，也叫作渐进时间复杂度（asymptotic time complexity），简称时间复杂度。

分析的实用方法：

1. 只关注循环执行次数最多的一段代码
2. 加法法则：总复杂度等于量级最大的那段代码的复杂度
3. 乘法法则：嵌套代码的复杂度等于嵌套内外代码复杂度的乘积
4. 递推公式分析法
5. 递归树分析法

### 常见的时间复杂度

![Big O](http://danthought.com/big-o.png)

- 多项式量级
    - 常量阶 O(1)
    - 对数阶 O(logn)
    - 线性阶 O(n)
    - 线性对数阶 O(nlogn)
    - 平方阶 O(n2) 立方阶 O(n3)
- 非多项式量级 当数据规模 n 越来越大时，非多项式量级算法的执行时间会急剧增加，求解问题的执行时间会无限增长。
    - 指数阶 O(2n)
    - 阶乘阶 O(n!)

### 空间复杂度分析

空间复杂度全称就是渐进空间复杂度（asymptotic space complexity），表示算法的存储空间与数据规模之间的增长关系。注意说空间复杂度的时候，是指除了原本的数据存储空间外，算法运行还需要额外的存储空间。

### 最好情况时间复杂度

最好情况时间复杂度（best case time complexity）就是，在最理想的情况下，执行这段代码的时间复杂度。

### 最坏情况时间复杂度

最坏情况时间复杂度（worst case time complexity）就是，在最糟糕的情况下，执行这段代码的时间复杂度。

### 平均情况时间复杂度

平均情况时间复杂度（average case time complexity）把每种情况发生的概率也考虑进去，每种情况操作的耗时乘以其发生的概率，这个值就是概率论中的加权平均值，也叫作期望值，所以平均时间复杂度的全称应该叫加权平均时间复杂度或者期望时间复杂度。

### 均摊时间复杂度

均摊时间复杂度（amortized time complexity）就是一种特殊的平均时间复杂度，对一个数据结构进行一组连续操作中，大部分情况下时间复杂度都很低，只有个别情况下时间复杂度比较高，而且这些操作之间存在前后连贯的时序关系，这个时候，我们就可以将这一组操作放在一块儿分析，看是否能将较高时间复杂度那次操作的耗时，平摊到其他那些时间复杂度比较低的操作上。而且，在能够应用均摊时间复杂度分析的场合，一般均摊时间复杂度就等于最好情况时间复杂度。

## 🔢 数组 Array

### 定义

数组（Array）是一种线性表数据结构。它用一组连续的内存空间，来存储一组具有相同类型的数据。

第一是线性表（Linear List）。顾名思义，线性表就是数据排成像一条线一样的结构。每个线性表上的数据最多只有前和后两个方向。其实除了数组，链表、队列、栈等也是线性表结构。

第二个是连续的内存空间和相同类型的数据。正是因为这两个限制，它才有了一个堪称“杀手锏”的特性：“随机访问”。但有利就有弊，这两个限制也让数组的很多操作变得非常低效，比如要想在数组中删除、插入一个数据，为了保证连续性，就需要做大量的数据搬移工作。

### 低效的插入

假设数组的长度为 n，现在，如果我们需要将一个数据插入到数组中的第 k 个位置。为了把第 k 个位置腾出来，给新来的数据，我们需要将第 k～n 这部分的元素都顺序地往后挪一位。平均情况时间复杂度为 (1 + 2 + … n) / n = O(n)。

如果数组中存储的数据并没有任何规律，数组只是被当作一个存储数据的集合。在这种情况下，如果要将某个数据插入到第 k 个位置，为了避免大规模的数据搬移，我们还有一个简单的办法就是，直接将第 k 位的数据搬移到数组元素的最后，把新的元素直接放入第 k 个位置。利用这种处理技巧，在特定场景下，在第 k 个位置插入一个元素的时间复杂度就会降为 O(1)。

### 低效的删除

跟插入数据类似，如果我们要删除第 k 个位置的数据，为了内存的连续性，也需要搬移数据，不然中间就会出现空洞，内存就不连续了。和插入类似，如果删除数组末尾的数据，则最好情况时间复杂度为 O(1)；如果删除开头的数据，则最坏情况时间复杂度为 O(n)；平均情况时间复杂度也为 O(n)。

每次的删除操作并不是真正地搬移数据，只是记录数据已经被删除。当数组没有更多空间存储数据时，我们再触发执行一次真正的删除操作，这样就大大减少了删除操作导致的数据搬移。

### 数组中重复的数字

- 长度为 n 的数组里的所有数字都在 0～n-1 的范围内。数组中某些数字是重复的，但不知道有几个数字重复了，也不知道每个数字重复了几次，找出数组中任意一个重复的数字。例如，如果输入长度为 7 的数组 { 2，3，1，0，2，5，3 }，那么对应的输出是重复的数字 2 或者 3。
    - 排序
    - 利用哈希表来解决这个问题。从头到尾按顺序扫描数组的每个数字，每扫描到一个数字的时候，都可以用 O(1) 的时间来判断哈希表里是否已经包含了该数字。如果哈希表里还没有这个数字，就把它加入哈希表。如果哈希表里已经存在该数字，就找到一个重复的数字。这个算法的时间杂度是 O(n)，但它提高时间效率是以一个大小为 O(m) 的哈希表为代价的。
    - [从头到尾依次扫描这个数组中的每个数字。扫描到下标为 i 的数字时，首先比较这个数字（用 m 表示）是不是等于 i。如果是，则接着扫描下一个数字;如果不是，则再拿它和第 m 个数字进行比较。如果它和第 m 个数字相等，就找到了一个重复的数字（该数字在下标为 i 和 m 的位置都出现了）;如果它和第 m 个数字不相等，就把第 i 个数字和第 m 个数字交换，把 m 放到属于它的位置。接下来再重复这个比较、交换的过程，直到我们发现一个重复的数字。](Array/find_duplicate_number_of_array.cpp)
- 在一个长度为 n+1 的数组里的所有数字都在 1～n 的范围内，所以数组中至少有一个数字是重复的。请找出数组中任意一个重复的数字，但不能修改输入的数组。例如，如果输入长度为 8 的数组 { 2，3，5，4，3，2，6，7 }，那么对应的输出是重复的数字 2 或者 3。 
    - 哈希表
    - [把从 1～n 的数字从中间的数字 m 分为两部分，前面一半为 1～m，后面一半为 m+1～n。如果 1～m 的数字的数目超过 m，那么这一半的区间一定包含重复的数字;否则，另一半 m+1～n 的区间里一定包含重复的数字。我们可以继续把包含重复数字的区间一分为二，直到找到一个重复的数字。这个过程和二分查找算法很类似，只是多了一步统计区间里数字的数目。 ](Array/find_duplicate_number_of_array.cpp)
- [在一个二维数组中，每一行都按照从左到右递增的顺序，每一列都按照从上到下递增的顺序排序。请完成一个函数，输入这样的一个二维数组和一个整数，判断数组中是否含有该整数。 首先选取数组中右上角的数字，如果该数字等于要查找的数字，则查找过程结束；如果该数字大要查找的数字，则剔除这个数字所在的列；如果该数字小于要查找的数字，则剔除这个数字所在的行。也就是说，如果要查找的数字不在数组的右上角，则每一次都在数组的查找范围中剔除一行或者一列，这样每一步都可以缩小查找的范围，直到找到要查找的数字，或者查找范围为空。](Array/find_number_of_matrix.cpp)
- [输入一个整数数组，实现一个函数来调整该数组中数字的顺序得所有奇数位于数组的前半部分，所有偶数位于数组的后半部分。把数组中的数按照大小分为两部分，所有负数都在非负数的前面。把数组中的数分为两部分，能被 3 整除的数都在不能被 3 整除的数的前面。参考 Partition](Array/divide_array.cpp)

## 🔗 链表 Link List

### 定义

数组需要一块连续的内存空间来存储，对内存的要求比较高，而链表恰恰相反，它并不需要一块连续的内存空间，它通过“指针”将一组零散的内存块串联起来使用。

数组简单易用，在实现上使用的是连续的内存空间，可以借助 CPU 的缓存机制，预读数组中的数据，所以访问效率更高。而链表在内存中并不是连续存储，所以对 CPU 缓存不友好，没办法有效预读。

除此之外，如果你的代码对内存的使用非常苛刻，那数组就更适合你。因为链表中的每个结点都需要消耗额外的存储空间去存储一份指向下一个结点的指针，所以内存消耗会翻倍。而且，对链表进行频繁的插入、删除操作，还会导致频繁的内存申请和释放，容易造成内存碎片，如果是 Java 语言，就有可能会导致频繁的 GC（Garbage Collection，垃圾回收）。

### 测试用例

- [链表包含多个结点](Google_tests/LinkList/NormalLinkListTest.cpp)
- [链表只包含两个结点](Google_tests/LinkList/TwoNodesLinkListTest.cpp)
- [链表只包含一个结点](Google_tests/LinkList/OneNodeLinkListTest.cpp)
- [链表为空](Google_tests/LinkList/EmptyLinkListTest.cpp)

### 基本的增删查

- 对于单向链表，增加和删除都要先找到前驱节点，只能一个个地查找，所以为 O(n)。
- 针对链表的插入、删除操作，需要对插入第一个结点和删除最后一个结点的情况进行特殊处理。如果我们引入哨兵结点，在任何时候，不管链表是不是空，head 指针都会一直指向这个哨兵结点。我们也把这种有哨兵结点的链表叫带头链表。相反，没有哨兵结点的链表就叫作不带头链表。
- [某个指定结点前面插入一个结点：双向链表可以在 O(1) 时间复杂度搞定，而单向链表需要 O(n) 的时间复杂度。](LinkList/link_list_append_node.cpp)
- [删除给定指针指向的结点：因为双向链表中的结点已经保存了前驱结点的指针，不需要像单链表那样遍历。所以，单链表删除操作需要 O(n) 的时间复杂度，而双向链表只需要在 O(1) 的时间复杂度内就搞定了。](LinkList/link_list_remove_node.cpp)

### 增删时，考虑被操作的节点在头部、中间和尾部的情况

- [两个有序（从小到大）单链表，构造一条新链表，包含同时出现在两个链表的节点](LinkList/intersect_two_sorted_link_list.cpp)
- [给定的一个节点指针，在 O(1) 时间内，删除链表节点](LinkList/link_list_remove_node.cpp)
- [在一个排序的链表中删除重复节点](LinkList/link_list_remove_node.cpp)
- [反转链表](LinkList/reverse_link_list.cpp)
- [合并两个排序的链表](LinkList/merge_link_list.cpp)

### 查询时，考虑多个指向不同位置的指针：快慢指针，相隔一定距离的指针

- [从尾到头打印链表](LinkList/print_link_list_reverse.cpp)
- [从链表中找出中间的节点](LinkList/find_middle_node_of_link_list.cpp)
- [从链表中找出倒数第 k 个节点，如 1、2、3、4、5、6，倒数第 3 个节点是 4，删除链表倒数第 n 个结点思路和这个相同](LinkList/find_kth_to_tail_of_link_list.cpp)
- [从链表中找出环的入口节点（含链表中环的检测的步骤）](LinkList/entry_node_of_loop_link_list.cpp)
- [两个链表的第一个公共节点](LinkList/find_first_common_node_of_link_list.cpp)
- [单向链表存储的字符串，判断其是否是回文字符串](LinkList/check_palindromic_string_in_link_list.cpp)

### 链表来实现缓存淘汰策略

- [先进先出策略 FIFO（First In，First Out）](LinkList/find_node_of_cache_in_link_list.cpp)：链表实现的队列；访问数据时，已经缓存的数据，直接返回；没有缓存的数据，缓存未满，新数据直接添加到链表的尾部；缓存已经满，则删除链表头节点，新数据再添加到链表的尾部。
- [最少使用策略 LFU（Least Frequently Used）](LinkList/find_node_of_cache_in_link_list.cpp)：链表按访问次数排序；访问数据时，已经缓存的数据，次数加一，再排序；没有缓存的数据，缓存未满，新数据直接添加到链表的尾部；缓存已经满，则删除链表尾节点，新数据再添加到链表的尾部。
- [最近最少使用策略 LRU（Least Recently Used）](LinkList/find_node_of_cache_in_link_list.cpp)：链表按最近访问时间排序；访问数据时，已经缓存的数据，移动到链表头部；没有缓存的数据，缓存未满，新数据直接插入到链表的头部；缓存已经满，则删除链表尾节点，新数据再插入到链表的头部。

## 🚦 栈和队列 Stack and Queue

### 栈的定义

当某个数据集合只涉及在一端插入和删除数据，并且满足后进先出、先进后出的特性，我们就应该首选“栈”这种数据结构。

### 栈的应用

- 栈在函数调用中的应用：操作系统给每个线程分配了一块独立的内存空间，这块内存被组织成“栈”这种结构, 用来存储函数调用时的临时变量。每进入一个函数，就会将临时变量作为一个栈帧入栈，当被调用函数执行完成，返回之后，将这个函数对应的栈帧出栈。
- 栈在表达式求值中的应用：比如：34+13*9+44-12/3。对于这个四则运算，编译器就是通过两个栈来实现的。其中一个保存操作数的栈，另一个是保存运算符的栈。我们从左向右遍历表达式，当遇到数字，我们就直接压入操作数栈；当遇到运算符，就与运算符栈的栈顶元素进行比较。如果比运算符栈顶元素的优先级高，就将当前运算符压入栈；如果比运算符栈顶元素的优先级低或者相同，从运算符栈中取栈顶运算符，从操作数栈的栈顶取 2 个操作数，然后进行计算，再把计算完的结果压入操作数栈，继续比较。
- 栈在括号匹配中的应用：{[] ()[{}]} 或 [{()}([])] 等都为合法格式，而 {[}()] 或 [({)] 为不合法的格式。用栈来保存未匹配的左括号，从左到右依次扫描字符串。当扫描到左括号时，则将其压入栈中；当扫描到右括号时，从栈顶取出一个左括号。如果能够匹配，则继续扫描剩下的字符串。如果扫描的过程中，遇到不能配对的右括号，或者栈中没有数据，则说明为非法格式。
- 实现浏览器的前进、后退功能：使用两个栈，X 和 Y，我们把首次浏览的页面依次压入栈 X，当点击后退按钮时，再依次从栈 X 中出栈，并将出栈的数据依次放入栈 Y。当我们点击前进按钮时，我们依次从栈 Y 中取出数据，放入栈 X 中。当栈 X 中没有数据时，那就说明没有页面可以继续后退浏览了。当栈 Y 中没有数据，那就说明没有页面可以点击前进按钮浏览了。

### 队列的定义

入队 enqueue()，放一个数据到队列尾部；出队 dequeue()，从队列头部取一个元素。

### 队列的应用

- 阻塞队列其实就是在队列基础上增加了阻塞操作。简单来说，就是在队列为空的时候，从队头取数据会被阻塞。因为此时还没有数据可取，直到队列中有了数据才能返回；如果队列已经满了，那么插入数据的操作就会被阻塞，直到队列中有空闲位置后再插入数据，然后再返回。线程安全的队列我们叫作并发队列。最简单直接的实现方式是直接在 enqueue()、dequeue() 方法上加锁，但是锁粒度大并发度会比较低，同一时刻仅允许一个存或者取操作。
- 实际上，对于大部分资源有限的场景，当没有空闲资源时，基本上都可以通过“队列”这种数据结构来实现请求排队。

### 数据插入和删除的特性

- [顺序栈：用数组实现的栈](StackAndQueue/stack.cpp) ，注意空和满的情况；支持动态扩容的顺序栈，入栈操作来说，最好情况时间复杂度是 O(1)，最坏情况时间复杂度是 O(n)，均摊时间复杂度是 O(1)
- [链式栈：用链表实现的栈](StackAndQueue/stack.cpp) ，注意空的情况，最好用双向链表
- [包含 min 函数的栈，输出栈中的最小值](StackAndQueue/stack.cpp) 
- [输入两个整数序列，第一个序列表示栈的压入顺序，判断第二个序列是否为该栈的弹出顺序](StackAndQueue/is_pop_order_of_stack.cpp) 
- [顺序队列：用数组实现的队列](StackAndQueue/queue.cpp)，注意空和满的情况，入队操作可能需要数据移动
- [链式队列：用链表实现的队列](StackAndQueue/queue.cpp)，注意空的情况
- [循环队列：用数组实现的循环队列](StackAndQueue/queue.cpp)，注意空和满的情况，空一个位置不存储数据
- [两个栈实现队列](StackAndQueue/queue.cpp) 

## ♻️ 递归和循环 Recursion and Loop

### 递归需要满足的三个条件

- 一个问题的解可以分解为几个子问题的解。
- 这个问题与分解之后的子问题，除了数据规模不同，求解思路完全一样。
- 存在递归终止条件。

### 如何编写递归代码？

- 写递归代码的关键就是找到如何将大问题分解为小问题的规律，并且基于此写出递推公式，然后再推敲终止条件，最后将递推公式和终止条件翻译成代码。

### 递归的优缺点

- 递归实现的代码简洁。
- 递归代码要警惕堆栈溢出，递归层次太深，空间复杂度就高，改为采用循环，或者需要在内存堆上实现栈，手动模拟入栈、出栈过程。
- 递归代码要警惕重复计算，复用之前的计算结果可以提高时间效率。

### 注意重复计算降低时间效率

- [斐波那契数列](RecursionAndLoop/fibonacci.cpp)；青蛙跳台阶：一只青蛙一次可以跳上 1 级台阶，也可以跳上 2 级台阶，该青蛙跳上一个 n 级的台阶总共有多少种跳法。
- [n 个骰子的点数：把 n 个骰子仍在地上，所有骰子朝上一面的点数之和为 s，输入 n，打印出 s 的所有可能的值出现的概率。](RecursionAndLoop/print_dice_probability.cpp)

## 🎰 排序 Sort

### 如何分析一个“排序算法”

- 排序算法的执行效率：最好情况、最坏情况、平均情况时间复杂度，时间复杂度的系数、常数 、低阶，比较次数和交换（或移动）次数。
- 排序算法的内存消耗：原地排序算法，就是特指空间复杂度是 O(1) 的排序算法。
- 排序算法的稳定性：如果待排序的序列中存在值相等的元素，经过排序之后，相等元素之间原有的先后顺序不变。

### 平方阶 O(n2) 的排序算法 

|      | 是原地排序？ | 是否稳定？ | 最好 | 最坏 | 平均 |
| ---- | ---- | ---- | ---- | ---- | ---- |
| [冒泡排序](SortAndFind/bubble_sort.cpp) | 是 | 是 | 线性阶 O(n) | 平方阶 O(n2) | 平方阶 O(n2) |
| [插入排序](SortAndFind/insertion_sort.cpp) | 是 | 是 | 线性阶 O(n) | 平方阶 O(n2) | 平方阶 O(n2) |
| [选择排序](SortAndFind/selection_sort.cpp) | 是 | 否 | 平方阶 O(n2) | 平方阶 O(n2) | 平方阶 O(n2) |

- 选择排序是一种不稳定的排序算法，比如 5，8，5，2，9 这样一组数据，使用选择排序算法来排序的话，第一次找到最小元素 2，与第一个 5 交换位置，那第一个 5 和中间的 5 顺序就变了，所以就不稳定了。
- 冒泡排序和插入排序的比较：冒泡排序的数据交换要比插入排序的数据移动要复杂，冒泡排序需要 3 个赋值操作，而插入排序只需要 1 个；随机生成 10000 个数组，每个数组中包含 200 个数据，然后在我的机器上分别用冒泡和插入排序算法来排序，冒泡排序算法大约 700ms 才能执行完成，而插入排序只需要 100ms 左右就能搞定。

### 线性对数阶 O(nlogn) 的排序算法 

|      | 是原地排序？ | 是否稳定？ | 最好 | 最坏 | 平均 |
| ---- | ---- | ---- | ---- | ---- | ---- |
| [归并排序](SortAndFind/merge_sort.cpp) | 否 | 是 | 线性对数阶 O(nlogn) | 线性对数阶 O(nlogn) | 线性对数阶 O(nlogn) |
| [快速排序](SortAndFind/quick_sort.cpp) | 是 | 否 | 线性对数阶 O(nlogn) | 平方阶 O(n2) | 线性对数阶 O(nlogn) |
| [堆排序](SortAndFind/heap_sort.cpp) | 是 | 否 | 线性对数阶 O(nlogn) | 线性对数阶 O(nlogn) | 线性对数阶 O(nlogn) |

- 注意通过数组下标来操作范围。
- 归并排序的空间复杂度是 O(n)。
- 通过合理地选择 pivot 来避免快速排序算法时间复杂度退化到 O(n2)，被分区点分开的两个分区中，数据的数量差不多：
    - 三数取中法：我们从区间的首、尾、中间，分别取出一个数，然后对比大小，取这 3 个数的中间值作为分区点。这样每间隔某个固定的长度，取数据出来比较，将中间值作为分区点的分区算法，肯定要比单纯取某一个数据更好。但是，如果要排序的数组比较大，那“三数取中”可能就不够了，可能要“五数取中”或者“十数取中”。
    - 随机法：随机法就是每次从要排序的区间中，随机选择一个元素作为分区点。这种方法并不能保证每次分区点都选的比较好，但是从概率的角度来看，也不大可能会出现每次分区点都选得很差的情况，所以平均情况下，这样选的分区点是比较好的。时间复杂度退化为最糟糕的 O(n2) 的情况，出现的可能性不大。  
- 归并排序和快速排序的比较：快排和归并用的都是分治思想，归并排序的处理过程是由下到上的，先处理子问题，然后再合并；而快排正好相反，它的处理过程是由上到下的，先分区，然后再处理子问题。

#### 类似快速排序中的 Partition

- [求无序数组中的第 K 大元素：在 O(n) 时间复杂度内求无序数组中的第 K 大元素。比如，4， 2， 5， 12， 3 这样一组数据，第 3 大元素就是 4。](SortAndFind/find_max_kth_in_unsorted_array.cpp)
- [数组中出现次数超过一半的数字：数组中有一个数字出现的次数超过数组长度的一半，请找出过 个数字。例如，输入一个长度为9的数组{1，2，3，2，2，2，5，4，2}。由于数字组中出现了5次，超过数组长度的一半，因此输出2。解法 1 根据 Partition。解法 2，数组中有一个数字出现的次数超过数组长度的一半，也就是说它出现的次数比其他所有数字出现次数的和还要多。因此，我们可以考虑在遍历数组的时候保存两个值∶一个是数组中的一个数字;另一个是次数。当我们遍历到下一个数字的时候，如果下一个数字和我们之前保存的数字相同，则次数加1;如果下一个数字和我们之前保存的数字不同，则次数减1。如果次数为零，那么我们需要份存下一个数字，并把次数设为1。由于我们要找的数字出现的次数比其他所有数字出现的次数之和还要多，那么要找的数字肯定是最后一次把次数设为1时对应的数字。](SortAndFind/find_more_than_half_number_in_unsorted_array.cpp)
- [最小的 k 个数：输入 n 个整数，找出其中最小的 k 个数。例如，输入 4、5、1、6、2、7、3、8 这 8 个数字，则最小的 4 个数字是 1、2、3、4。解法 1 根据 Partition。解法 2 根据最大堆。](SortAndFind/find_min_kth_in_unsorted_array.cpp)

### 线性阶 O(n) 的线性排序算法

线性排序（Linear sort）。之所以能做到线性的时间复杂度，主要原因是，这三个算法是非基于比较的排序算法，都不涉及元素之间的比较操作。

#### 桶排序（Bucket sort）

首先，我们来看桶排序。桶排序，顾名思义，会用到“桶”，核心思想是将要排序的数据分到几个有序的桶里，每个桶里的数据再单独进行排序。桶内排完序之后，再把每个桶里的数据按照顺序依次取出，组成的序列就是有序的了。

如果要排序的数据有 n 个，我们把它们均匀地划分到 m 个桶内，每个桶里就有 k=n/m 个元素。每个桶内部使用快速排序，时间复杂度为 O(k * logk)。m 个桶排序的时间复杂度就是 O(m * k * logk)，因为 k=n/m，所以整个桶排序的时间复杂度就是 O(n*log(n/m))。当桶的个数 m 接近数据个数 n 时，log(n/m) 就是一个非常小的常量，这个时候桶排序的时间复杂度接近 O(n)。

首先，要排序的数据需要很容易就能划分成 m 个桶，并且，桶与桶之间有着天然的大小顺序。这样每个桶内的数据都排序完之后，桶与桶之间的数据不需要再进行排序。

其次，数据在各个桶之间的分布是比较均匀的。如果数据经过桶的划分之后，有些桶里的数据非常多，有些非常少，很不平均，那桶内数据排序的时间复杂度就不是常量级了。在极端情况下，如果数据都被划分到一个桶里，那就退化为 O(nlogn) 的排序算法了。

桶排序比较适合用在外部排序中。所谓的外部排序就是数据存储在外部磁盘中，数据量比较大，内存有限，无法将数据全部加载到内存中。比如说我们有 10GB 的订单数据，我们希望按订单金额（假设金额都是正整数）进行排序，但是我们的内存有限，只有几百 MB，没办法一次性把 10GB 的数据都加载到内存中。这个时候该怎么办呢？将所有订单根据金额划分到 100 个桶里，那订单会被均匀划分到 100 个文件中，每个小文件中存储大约 100MB 的订单数据，针对这些划分之后还是比较大的文件，我们可以继续划分。

#### 计数排序（Counting sort）

计数排序其实是桶排序的一种特殊情况。当要排序的 n 个数据，所处的范围并不大的时候，比如最大值是 k，我们就可以把数据划分成 k 个桶。每个桶内的数据值都是相同的，省掉了桶内排序的时间。

因为只涉及扫描遍历操作，所以时间复杂度是 O(n)。

计数排序只能用在数据范围不大的场景中，如果数据范围 k 比要排序的数据 n 大很多，就不适合用计数排序了。而且，计数排序只能给非负整数排序，如果要排序的数据是其他类型的，要将其在不改变相对大小的情况下，转化为非负整数。

[从后到前依次扫描未排序数组。比如，当扫描到 3 时，我们可以从统计数组中取出下标为 3 的值 7，也就是说，到目前为止，包括自己在内，分数小于等于 3 的考生有 7 个，也就是说 3 是排序数组中的第 7 个元素（也就是排序数组中下标为 6 的位置）。当 3 放入到排序数组中后，小于等于 3 的元素就只剩下了 6 个了，所以相应的 统计数组[3] 要减 1，变成 6。](SortAndFind/counting_sort.cpp)

#### 基数排序（Radix sort）

假设我们有 10 万个手机号码，希望将这 10 万个手机号码从小到大排序。

先按照最后一位来排序手机号码，然后，再按照倒数第二位重新排序，以此类推，最后按照第一位重新排序。经过 11 次排序之后，手机号码就都有序了。这里按照每位来排序的排序算法要是稳定的。

根据每一位来排序，我们可以用刚讲过的桶排序或者计数排序，它们的时间复杂度可以做到 O(n)。如果要排序的数据有 k 位，那我们就需要 k 次桶排序或者计数排序，总的时间复杂度是 O(k*n)。当 k 不大的时候，比如手机号码排序的例子，k 最大就是 11，所以基数排序的时间复杂度就近似于 O(n)。

有时候要排序的数据并不都是等长的，我们可以把所有的单词补齐到相同长度，位数不够的可以在后面补“0”，因为根据 ASCII 值，所有字母都大于“0”，所以补“0”不会影响到原有的大小顺序。

基数排序对要排序的数据是有要求的，需要可以分割出独立的“位”来比较，而且位之间有递进的关系，如果 a 数据的高位比 b 数据大，那剩下的低位就不用比较了。除此之外，每一位的数据范围不能太大，要可以用线性排序算法来排序，否则，基数排序的时间复杂度就无法做到 O(n) 了。

### stdlib.h 中的 qsort()

qsort() 对于小数据量的排序，会优先使用归并排序来排序输入数据；要排序的数据量比较大的时候，qsort() 会改为用快速排序算法来排序，qsort() 选择分区点的方法就是“三数取中法”，递归太深会导致堆栈溢出的问题，qsort() 是通过自己实现一个堆上的栈，手动模拟递归来解决的；当要排序的区间中，元素的个数小于等于 4 时，qsort() 就退化为插入排序。

## ↔️ 二分查找 Binary Search

二分查找针对的是一个有序的数据集合，查找思想有点类似分治思想。每次都通过跟区间的中间元素对比，将待查找的区间缩小为之前的一半，直到找到要查找的元素，或者区间被缩小为 0。我们假设数据大小是 n，每次查找后数据都会缩小为原来的一半，也就是会除以 2，时间复杂度就是 O(logn)。

### 注意循环退出条件、middle 的取值、low 和 high 的更新

- [有序数组中不存在重复元素的二分查找](SortAndFind/binary_search.cpp)
- [求一个数的平方根，要求精确到小数点后 6 位](SortAndFind/sqrt.cpp)

### 二分查找应用场景的局限性

- 首先，二分查找依赖的是顺序表结构，简单点说就是数组。主要原因是二分查找算法需要按照下标随机访问元素，所以链表是不行的。
- 其次，二分查找针对的是有序数据。二分查找只能用在插入、删除操作不频繁，一次排序多次查找的场景中。
- 再次，数据量太小不适合二分查找。如果要处理的数据量很小，完全没有必要用二分查找，顺序遍历就足够了。
- 最后，数据量太大也不适合二分查找。二分查找的底层需要依赖数组这种数据结构，而数组为了支持随机访问的特性，要求内存空间连续，对内存的要求比较苛刻。

### 二分查找的变形问题，有序数组中有重复元素

- [查找第一个值等于给定值的元素](SortAndFind/binary_search.cpp)，如果 mid 等于 0，那这个元素已经是数组的第一个元素，那它肯定是我们要找的；如果 mid 不等于 0，但 a[mid]的前一个元素 a[mid-1]不等于 value，那也说明 a[mid]就是我们要找的第一个值等于给定值的元素。
- [查找最后一个值等于给定值的元素](SortAndFind/binary_search.cpp)
- [查找第一个大于等于给定值的元素](SortAndFind/binary_search.cpp)
- [查找最后一个小于等于给定值的元素](SortAndFind/binary_search.cpp)
- 定位出一个 IP 地址的归属地：如果 IP 区间与归属地的对应关系不经常更新，我们可以先预处理这 12 万条数据，让其按照起始 IP 从小到大排序。IP 地址可以转化为 32 位的整型数。所以，我们可以将起始地址，按照对应的整型值的大小关系，从小到大进行排序。当我们要查询某个 IP 归属地时，我们可以先通过二分查找，找到最后一个起始 IP 小于等于这个 IP 的 IP 区间，然后，检查这个 IP 是否在这个 IP 区间内，如果在，我们就取出对应的归属地显示；如果不在，就返回未查找到。

### 有序数组的旋转

- 把一个数组最开始的若干个元素搬到数组的末尾，称之为数组的旋转，例如，数组 {3, 4, 5, 1, 2} 为 {1, 2, 3, 4, 5} 的一个旋转。
- [输入一个递增排序的数组的一个旋转，输出旋转数组的最小元素，如果当前查找的范围存在重复值，就需要退化为顺序查找。](SortAndFind/rotated_array.cpp)
- [在一个递增排序的数组的一个旋转中查找指定值。](SortAndFind/rotated_array.cpp)

### 数组是排序就应该想到使用二分查找

- [统计一个数字在排序数组中出现的次数，转换为查找第一个值等于给定值的元素和查找最后一个值等于给定值的元素，根据下标算次数。](SortAndFind/binary_search2.cpp)
- [一个长度为 n - 1 的递增排序数组中的所有数字都是唯一的，并且每个数字都在范围 0~n-1 之内。在范围 0~n-1 内的 n 个数字中有且只有一个数字不在该数组中，找出这个数字，转换为查找数组中第一个数值和下标不相等的元素。](SortAndFind/binary_search2.cpp)
- [在一个单调递增的数组里每个元素都是整数并且是唯一的，找出数组中任意一个数值等于其下标的元素](SortAndFind/binary_search2.cpp)

## ⛓ 跳表 Skip List

跳表使用空间换时间的设计思路，通过构建多级索引来提高查询的效率，实现了基于链表的“二分查找”。跳表是一种动态数据结构，支持快速地插入、删除、查找操作，时间复杂度都是 O(logn)。跳表的空间复杂度是 O(n)。不过，跳表的实现非常灵活，可以通过改变索引构建策略，有效平衡执行效率和内存消耗。

## 🗂 散列表 Hash Table

散列表用的是数组支持按照下标随机访问数据的特性，所以散列表其实就是数组的一种扩展，由数组演化而来。可以说，如果没有数组，就没有散列表。

假如我们有 89 名选手参加学校运动会，编号用 6 位数字来表示。比如 051167，其中，前两位 05 表示年级，中间两位 11 表示班级，最后两位还是原来的编号 1 到 89。其中，参赛选手的编号我们叫做键（key）或者关键字。我们用它来标识一个选手。我们把参赛编号转化为数组下标的映射方法就叫作散列函数（或“Hash 函数”“哈希函数”），而散列函数计算得到的值就叫作散列值（或“Hash 值”“哈希值”）。

### 散列函数

hash(key)，其中 key 表示元素的键值，hash(key) 的值表示经过散列函数计算得到的散列值。

散列函数设计的基本要求：

- 散列函数计算得到的散列值是一个非负整数；
- 如果 key1 == key2，那 hash(key1) == hash(key2)；
- 如果 key1 ≠ key2，那 hash(key1) ≠ hash(key2)。真实的情况下，要想找到一个不同的 key 对应的散列值都不一样的散列函数，几乎是不可能的，无法完全避免这种散列冲突。

要尽可能让散列后的值随机且均匀分布，这样会尽可能地减少散列冲突，即便冲突之后，分配到每个槽内的数据也比较均匀。除此之外，散列函数的设计也不能太复杂，太复杂就会太耗时间，也会影响散列表的性能。

### 装载因子和动态扩容

不管采用哪种探测方法，当散列表中空闲位置不多的时候，散列冲突的概率就会大大提高。用装载因子（load factor）来表示空位的多少：

    散列表的装载因子 = 填入表中的元素个数 / 散列表的长度
    
针对散列表，当装载因子过大时，我们也可以进行动态扩容，重新申请一个更大的散列表，将数据搬移到这个新散列表中，通过散列函数重新计算每个数据的存储位置。为了解决一次性扩容耗时过多的情况，我们可以将扩容操作穿插在插入操作的过程中，分批完成。当装载因子触达阈值之后，我们只申请新空间，但并不将老的数据搬移到新散列表中。当有新数据要插入时，我们将新数据插入新散列表中，并且从老的散列表中拿出一个数据放入到新散列表。每次插入一个数据到散列表，我们都重复上面的过程。经过多次插入操作之后，老的散列表中的数据就一点一点全部搬移到新散列表中了。这样没有了集中的一次性数据搬移，插入操作就都变得很快了。

### 散列冲突

大部分情况下，链表法更加普适。基于链表的散列冲突处理方法比较适合存储大对象、大数据量的散列表，也就是链表的优缺点，而且，比起开放寻址法，它更加灵活，支持更多的优化策略，比如用跳表、红黑树代替链表，来避免散列表时间复杂度退化成 O(n)，抵御散列碰撞攻击。但是，对于小规模数据、装载因子不高的散列表，比较适合用开放寻址法，也就是数组的优缺点。

#### 开放寻址法

开放寻址法的核心思想是，如果出现了散列冲突，我们就重新探测一个空闲位置，将其插入。

重新探测新的位置：

- 线性探测（Linear Probing），往散列表中插入数据时，如果某个数据经过散列函数散列之后，存储位置已经被占用了，我们就从当前位置开始，依次往后查找，看是否有空闲位置，直到找到为止。
- 二次探测（Quadratic Probing），所谓二次探测，跟线性探测很像，线性探测每次探测的步长是 1，而二次探测探测的步长就变成了原来的“二次方”。
- 双重散列（Double hashing），意思就是不仅要使用一个散列函数。我们使用一组散列函数 hash1(key)，hash2(key)，hash3(key)……我们先用第一个散列函数，如果计算得到的存储位置已经被占用，再用第二个散列函数，依次类推，直到找到空闲的存储位置。

#### 链表法

在散列表中，每个“桶（bucket）”或者“槽（slot）”会对应一条链表，所有散列值相同的元素我们都放到相同槽位对应的链表中。

### 散列表和链表常一起使用

- Word 文档中单词拼写检查功能是如何实现的：用的英文单词有 20 万个左右，假设单词的平均长度是 10 个字母，平均一个单词占用 10 个字节的内存空间，那 20 万英文单词大约占 2MB 的存储空间，就算放大 10 倍也就是 20MB。对于现在的计算机来说，这个大小完全可以放在内存里面。所以我们可以用散列表来存储整个英文单词词典。当用户输入某个英文单词时，我们拿用户输入的单词去散列表中查找。如果查到，则说明拼写正确；如果没有查到，则说明拼写可能有误，给予提示。借助散列表这种数据结构，我们就可以轻松实现快速判断是否存在拼写错误。
- 假设我们有 10 万条 URL 访问日志，如何按照访问次数给 URL 排序：遍历 10 万条数据，以 URL 为 key，访问次数为 value，存入散列表，同时记录下访问次数的最大值 K，时间复杂度 O(N)。如果 K 不是很大，可以使用桶排序，时间复杂度 O(N)。如果 K 非常大（比如大于 10 万），就使用快速排序，复杂度 O(NlogN)。
- 有两个字符串数组，每个数组大约有 10 万条字符串，如何快速找出两个数组中相同的字符串：以第一个字符串数组构建散列表，key 为字符串，value 为出现次数。再遍历第二个字符串数组，以字符串为 key 在散列表中查找，如果 value 大于零，说明存在相同字符串。时间复杂度 O(N)。
- LRU 缓存淘汰算法：使用散列表和双向链表，双向链表按最近访问时间排序，双向链表有头指针和尾指针，节点中包含数据、双向链表中的前驱指针、双向链表中的后继指针、散列表拉链中的后继指针；因为有了散列表，所以访问数据时，时间复杂度都是 O(1)；访问数据时，已经缓存的数据，移动到链表头部；没有缓存的数据，缓存未满，新数据直接插入到链表的头部；缓存已经满，则删除链表尾节点，新数据再插入到链表的头部。
- 假设猎聘网有 10 万名猎头，每个猎头都可以通过做任务（比如发布职位）来积累积分，然后通过积分来下载简历。假设你是猎聘网的一名工程师，如何在内存中存储这 10 万个猎头 ID 和积分信息，让它能够支持这样几个操作：根据猎头的 ID 快速查找、删除、更新这个猎头的积分信息（根据 ID 来构建散列表）；查找积分在某个区间的猎头 ID 列表（根据积分来构建跳表，通过跳表的二分查找，找到区间起始位置）；查找按照积分从小到大排名在第 x 位到第 y 位之间的猎头 ID 列表。（通过跳表的二分查找，找到区间起始位置）。

### 基于数组的字符散列表

- 如果需要判断多个字符是不是在某个字符串里出现过或者统计多个字符在某个字符串中出现的次数，那么我们可以考虑基于数组创建一个简单的散列表，这样可以用很小的空间消耗换来时间效率的提升。
- [在字符串中找出第一个只出现一次的字符，如输入"abaccdeff"，则输出'b'。](HashTable/char_hash_table.cpp)
- 定义一个函数，输入两个字符串，从第一个字符串中删除在第二个字符串中出现过的所有字符。例如，从第一个字符串"We are students."中删除在第二个字符串"aeiou"中出现过的字符得到的结果是"W r Stdnts."。为了解决这个问题，我们可以创建一个用数组实现的简单哈希表来存储第二个字符串。这样我们从头到尾扫描第一个字符串的每个字符时，用 O(1) 时间就能判断出该字符是不是在第一个字符串中。如果第一个字符串的长度是 n，那么总的时间复杂度是 O(n)。
- 定义一个函数，删除字符串中所有重复出现的字符。例如，输入"google"，删除重复的字符之后的结果是"gole"。这道题目和上面的问题比较类似，我们可以创建一个用布尔型数组实现的简单的哈希表。数组中的元素的意义是其下标看作 ASCII 码后对应的字母在字符串中是否已经出现。我们先把数组中所有的元素都设为 false。以"google"为例，当扫描到第一个 g 时，g 的 ASCII 码是 103，那我们把数组中下标为 103 的元素设为 true。当扫描到第二个 g 时，我们发现数组中下标为 103 的元素的值是 true，就知道 g 在前面已经出现过。也就是说，我们用 O(1) 时间就能判断出每个字符是否在前面已经出现过。如果字符串的长度是 n，那么总的时间复杂是 O(n)。
- 在英语中，如果两个单词中出现的字母相同，并且每个字母出现的次数也相同，那么这两个单词互为变位词。例如，silent 与 listen、evil 与 live 等互为变位词。请完成一个函数，判断输入两个字符串是不是互为变位词。我们可以创建一个用数组实现的简单哈希表，用来统计字符串中每个字符出现的次数。当扫描到第一个字符串中的每个字符时，为哈希表对应的项的值增加 1。接下来扫描第二个字符串，当扫描到每个字符时，为哈希表对应的项的减去 1。如果扫描完第二个字符串后，哈希表中所有的值都是 0，那么这两个字符串就互为变位词。
- [实现一个函数，用来找出字符串流中第一个只出现一次的字符，例如，当从字符流中只读出前两个字符"go"时，第一个只出现一次的字符是'g'；当从该字符流中读出前六个字符"google"时，第一个只出现一次的字符是'l'](HashTable/char_hash_table.cpp)

## 🔑 哈希 Hash

将任意长度的二进制值串映射为固定长度的二进制值串，这个映射的规则就是哈希算法，而通过原始数据映射之后得到的二进制值串就是哈希值。

需要满足的几点要求：

- 从哈希值不能反向推导出原始数据（所以哈希算法也叫单向哈希算法）；
- 对输入数据非常敏感，哪怕原始数据只修改了一个 Bit，最后得到的哈希值也大不相同；
- 散列冲突的概率要很小，对于不同的原始数据，哈希值相同的概率非常小；
- 哈希算法的执行效率要尽量高效，针对较长的文本，也能快速地计算出哈希值。

应用：

- 安全加密：加密的目的就是防止原始数据泄露，所以很难通过哈希值反向推导原始数据，这是一个最基本的要求。MD5 哈希值是固定的 128 位二进制串，能表示的数据是有限的，最多能表示 2^128 个数据，这个数据已经是一个天文数字了，所以散列冲突的概率要小于 1/2^128。
- 唯一标识：哈希算法可以对大数据做信息摘要，通过一个较短的二进制编码来表示很大的数据。每一个图片取一个唯一标识，或者说信息摘要。比如，我们可以从图片的二进制码串开头取 100 个字节，从中间取 100 个字节，从最后再取 100 个字节，然后将这 300 个字节放到一块，通过哈希算法（比如 MD5），得到一个哈希字符串，用它作为图片的唯一标识。
- 数据校验：从多个机器上并行下载一个 2GB 的电影，这个电影文件可能会被分割成很多文件块（比如可以分成 100 块，每块大约 20MB）。等所有的文件块都下载完成之后，再组装成一个完整的电影文件就行了。通过哈希算法，对 100 个文件块分别取哈希值，并且保存在种子文件中。当文件块下载完成之后，我们可以通过相同的哈希算法，对下载好的文件块逐一求哈希值，然后跟种子文件中保存的哈希值比对。如果不同，说明这个文件块不完整或者被篡改了，需要再重新从其他宿主机器上下载这个文件块。
- 散列函数：散列表对哈希算法的要求非常特别，更加看重的是散列的平均性和哈希算法的执行效率。
- 负载均衡：我们可以通过哈希算法，对客户端 IP 地址或者会话 ID 计算哈希值，将取得的哈希值与服务器列表的大小进行取模运算，最终得到的值就是应该被路由到的服务器编号。
- 数据分片
    - 假如我们有 1T 的日志文件，这里面记录了用户的搜索关键词，我们想要快速统计出每个关键词被搜索的次数，先把日志文件分成 n 份，同时在 n 个机器上，分别从搜索记录的日志文件中，依次读出每个搜索关键词，并且通过哈希函数计算哈希值，然后再跟 n 取模，最终得到的值，就是应该被分配到的机器编号。这样，哈希值相同的搜索关键词就被分配到了同一个机器上。每个机器会分别计算关键词出现的次数，最后合并起来就是最终的结果。
    - 假设现在我们的图库中有 1 亿张图片，我们准备 n 台机器，让每台机器只维护某一部分图片对应的散列表。我们每次从图库中读取一个图片，计算唯一标识，然后与机器个数 n 求余取模，得到的值就对应要分配的机器编号，然后将这个图片的唯一标识和图片路径发往对应的机器构建散列表。当我们要判断一个图片是否在图库中的时候，我们通过同样的哈希算法，计算这个图片的唯一标识，然后与机器个数 n 求余取模。假设得到的值是 k，那就去编号 k 的机器构建的散列表中查找。
- 分布式存储：通过哈希算法对数据取哈希值，然后对机器个数取模，这个最终值就是应该存储的缓存机器编号。

## 🌲 二叉树 Binary Tree

### 树

节点的高度 = 节点到叶子节点的最长路径
节点的深度 = 根节点到这个节点所经历的边的个数
节点的层数 = 节点的深度 + 1

树的高度 = 树的深度 = 根节点的高度
树的路径：从根节点开始往下一直到叶节点所经过的节点形成一条路径

### 二叉树

在二叉树中每个节点最多只能有两个节点。有链式存储法和顺序存储法。

- 给定一组数据，比如 1，3，5，6，9，10。你来算算，可以构建出多少种不同的二叉树？如果是完全二叉树，可以放在数组里面，简化为数组内的元素有多少种组合方式，这样的话，就是 n!

### 满二叉树

叶子节点全都在最底层，除了叶子节点之外，每个节点都有左右两个子节点，这种二叉树就叫做满二叉树。

### 完全二叉树

叶子节点都在最底下两层，最后一层的叶子节点都靠左排列，并且除了最后一层，其他层的节点个数都要达到最大，这种二叉树叫做完全二叉树。适合于顺序存储法。

### 二叉搜索树 Binary Search Tree (BST)

左子节点总是小于或等于根节点，而右子节点总是大于或等于根节点，平均在 O(logn) 的时间内根据数值在 BST 中找到一个节点。

- [二叉搜索树的查找](BinaryTree/binary_search_tree.cpp)，如果要查找的数据比根节点的值小，那就在左子树中递归查找；如果要查找的数据比根节点的值大，那就在右子树中递归查找。
- [二叉搜索树的查找最小节点](BinaryTree/binary_search_tree.cpp)，左子树中递归查找。
- [二叉搜索树的查找最大节点](BinaryTree/binary_search_tree.cpp)，右子树中递归查找。
- [二叉搜索树的插入](BinaryTree/binary_search_tree.cpp)，如果要插入的数据比节点的数据大，并且节点的右子树为空，就将新数据直接插到右子节点的位置；如果不为空，就再递归遍历右子树，查找插入位置。同理，如果要插入的数据比节点数值小，并且节点的左子树为空，就将新数据插入到左子节点的位置；如果不为空，就再递归遍历左子树，查找插入位置。
- [二叉搜索树的删除](BinaryTree/binary_search_tree.cpp)
    - 第一种情况是，如果要删除的节点没有子节点，只需要直接将父节点中，指向要删除节点的指针置为 null
    - 第二种情况是，如果要删除的节点只有一个子节点（只有左子节点或者右子节点），只需要更新父节点中，指向要删除节点的指针，让它指向要删除节点的子节点就可以了。
    - 第三种情况是，如果要删除的节点有两个子节点。需要找到这个节点的右子树中的最小节点，把它替换到要删除的节点上。然后再删除掉这个最小节点，因为最小节点肯定没有左子节点（如果有左子结点，那就不是最小节点了），所以，可以应用上面两条规则来删除这个最小节点。
- [二叉搜索树的前驱节点](BinaryTree/binary_search_tree.cpp)
    - 第一种情况，有左子树，左子树的最大节点就是前驱节点。
    - 第二种情况，无左子树，是父节点的右子节点，父节点就是前驱节点。
    - 第三种情况，无左子树，是父节点的左子节点，如果父节点有父节点且父节点是父父节点的左子节点，就一直往上走找一个祖先节点，其最低左子节点就是目标节点，祖先节点的父节点就是前驱节点。
- [二叉搜索树的后继节点](BinaryTree/binary_search_tree.cpp)
    - 第一种情况，有右子树，右子树的最小节点就是后继节点。
    - 第二种情况，无右子树，是父节点的左子节点，父节点就是后继节点。
    - 第三种情况，无右子树，是父节点的右子节点，如果父节点有父节点且父节点是父父节点的右子节点，就一直往上走找一个祖先节点，其最低右子节点就是目标节点，祖先节点的父节点就是后继节点。
- 时间复杂度分析：查找、插入、删除等很多操作的时间复杂度都跟树的高度成正比。两个极端情况的时间复杂度分别是 O(n) 和 O(logn)，分别对应二叉树退化成链表的情况和完全二叉树。
- 支持重复数据的二叉搜索树：第一种方法，二叉查找树中每一个节点不仅会存储一个数据，因此我们通过链表和支持动态扩容的数组等数据结构，把值相同的数据都存储在同一个节点上。第二种方法，每个节点仍然只存储一个数据，在查找插入位置的过程中，如果碰到一个节点的值，与要插入数据的值相同，我们就将这个要插入的数据放到这个节点的右子树，也就是说，把这个新插入的数据当作大于这个节点的值来处理。
- 散列表和二叉搜索树的比较
    - 第一，散列表中的数据是无序存储的，如果要输出有序的数据，需要先进行排序。而对于二叉查找树来说，我们只需要中序遍历，就可以在 O(n) 的时间复杂度内，输出有序的数据序列。
    - 第二，散列表扩容耗时很多，而且当遇到散列冲突时，性能不稳定，尽管二叉查找树的性能不稳定，但是在工程中，我们最常用的平衡二叉查找树的性能非常稳定，时间复杂度稳定在 O(logn)。
    - 第三，笼统地来说，尽管散列表的查找等操作的时间复杂度是常量级的，但因为哈希冲突的存在，这个常量不一定比 logn 小，所以实际的查找速度可能不一定比 O(logn) 快。加上哈希函数的耗时，也不一定就比平衡二叉查找树的效率高。
    - 第四，散列表的构造比二叉查找树要复杂，需要考虑的东西很多。比如散列函数的设计、冲突解决办法、扩容、缩容等。平衡二叉查找树只需要考虑平衡性这一个问题，而且这个问题的解决方案比较成熟、固定。
    - 最后，为了避免过多的散列冲突，散列表装载因子不能太大，特别是基于开放寻址法解决冲突的散列表，不然会浪费一定的存储空间。

### 平衡二叉树

严格定义：二叉树中任意一个节点的左右子树的高度相差不能大于 1。从这个定义来看，上一节我们讲的完全二叉树、满二叉树其实都是平衡二叉树，但是非完全二叉树也有可能是平衡二叉树。

不严格定义：平衡二叉查找树中“平衡”的意思，其实就是让整棵树左右看起来比较“对称”、比较“平衡”，不要出现左子树很高、右子树很矮的情况。这样就能让整棵树的高度相对来说低一些，相应的插入、删除、查找等操作的效率高一些。
 
### 红黑树 Red-Black Tree

红黑树是一种平衡二叉查找树。它是为了解决普通二叉查找树在数据更新的过程中，复杂度退化的问题而产生的。红黑树的高度近似 log2n，所以它是近似平衡，插入、删除、查找操作的时间复杂度都是 O(logn)。

一棵红黑树需要满足这样几个要求：

1. 红黑树中的节点，一类被标记为黑色，一类被标记为红色；
2. 根节点是黑色的；
3. 每个叶子节点都是黑色的空节点（NIL），也就是说，叶子节点不存储数据；
4. 任何相邻的节点都不能同时为红色，也就是说，红色节点是被黑色节点隔开的；
5. 每个节点，从该节点到达其可达叶子节点的所有路径，都包含相同数目的黑色节点；

在插入、删除节点的过程中，第 4 点、第 5点要求可能会被破坏，通过左旋和右旋等基本操作来恢复。

### 堆 Heap

#### 堆的定义

堆是一种特殊的树，只要满足下面这两点，它就是一个堆：

- 堆是一个完全二叉树；
- 堆中每一个节点的值都必须大于等于（或小于等于）其子树中每个节点的值。

对于每个节点的值都大于等于子树中每个节点值的堆，我们叫做 "大顶堆" 或 "最大堆"。对于每个节点的值都小于等于子树中每个节点值的堆，我们叫做 "小顶堆" 或 "最小堆"。

堆都支持哪些操作以及如何存储一个堆：

- 完全二叉树比较适合用数组来存储。用数组来存储完全二叉树是非常节省存储空间的。数组中下标为 0 的节点为空，数组中下标为 i 的节点，左子节点就是下标为 i\*2 的节点，右子节点就是下标为 i\*2+1 的节点，父节点就是下标为 i/2 的节点。
- [往堆中插入一个元素（从下往上的堆化方法）](BinaryTree/heap.cpp)：如果我们把新插入的元素放到堆的最后，让新插入的节点与父节点对比大小。如果不满足子节点小于等于父节点的大小关系，我们就互换两个节点。一直重复这个过程，直到父子节点之间满足刚说的那种大小关系。
- [删除堆顶元素（从上往下的堆化方法）](BinaryTree/heap.cpp)：把最后一个节点放到堆顶，然后利用同样的父子节点对比方法。对于不满足父子节点大小关系的，互换两个节点，并且重复进行这个过程，直到父子节点之间满足大小关系为止。
- 一个包含 n 个节点的完全二叉树，堆化的时间复杂度都是 O(logn)。

#### 堆排序 Heap Sort

整个堆排序的过程，都只需要极个别临时存储空间，所以堆排序是原地排序算法。堆排序包括建堆和排序两个操作，建堆过程的时间复杂度是 O(n)，排序过程的时间复杂度是 O(nlogn)，所以，堆排序整体的时间复杂度是 O(nlogn)。堆排序不是稳定的排序算法，因为在排序的过程，存在将堆的最后一个节点跟堆顶节点互换的操作，所以就有可能改变值相同数据的原始相对顺序。

- [建堆](SortAndFind/heap_sort.cpp)：第一种是借助我们前面讲的，在堆中插入一个元素的思路，时间复杂度就是 O(nlogn)。第二种实现思路，是从后往前处理数组，并且每个数据都是从上往下堆化，直接从第一个非叶子节点开始，依次堆化就行了，时间复杂度就是 O(n)。 
- [排序](SortAndFind/heap_sort.cpp)：当堆顶元素移除之后，我们把下标为 n 的元素放到堆顶，然后再通过堆化的方法，将剩下的 n−1 个元素重新构建成堆，时间复杂度是 O(nlogn)。

为什么快速排序要比堆排序性能好？

- 第一点，堆排序数据访问的方式没有快速排序友好。
- 第二点，对于同样的数据，在排序过程中，堆排序算法的数据交换次数要多于快速排序。

#### 堆的应用

优先级队列

- 用堆来实现是最直接、最高效的。一个堆就可以看作一个优先级队列。往优先级队列中插入一个元素，就相当于往堆中插入一个元素；从优先级队列中取出优先级最高的元素，就相当于取出堆顶元素。
- 合并有序小文件：假设我们有 100 个小文件，每个文件的大小是 100MB，每个文件中存储的都是有序的字符串。我们希望将这些 100 个小文件合并成一个有序的大文件。我们将从小文件中取出来的字符串放入到小顶堆中，那堆顶的元素，也就是优先级队列队首的元素，就是最小的字符串。我们将这个字符串放入到大文件中，并将其从堆中删除。然后再从小文件中取出下一个字符串，放入到堆中。
- 高性能定时器：假设我们有一个定时器，定时器中维护了很多定时任务，每个任务都设定了一个要触发执行的时间点。我们按照任务设定的执行时间，将这些任务存储在优先级队列中，队列首部（也就是小顶堆的堆顶）存储的是最先执行的任务。它拿队首任务的执行时间点，与当前时间点相减，得到一个时间间隔 T。这个时间间隔 T 就是，从当前时间开始，需要等待多久，才会有第一个任务需要被执行。这样，定时器就可以设定在 T 秒之后，再来执行任务。从当前时间点到（T-1）秒这段时间里，定时器都不需要做任何事情。当 T 秒时间过去之后，定时器取优先级队列中队首的任务执行。然后再计算新的队首任务的执行时间点与当前时间点的差值，把这个值作为定时器执行下一个任务需要等待的时间。

利用堆求 Top K

- 针对静态数据，如何在一个包含 n 个数据的数组中，查找前 K 大数据呢？我们可以维护一个大小为 K 的小顶堆，顺序遍历数组，从数组中取出数据与堆顶元素比较。如果比堆顶元素大，我们就把堆顶元素删除，并且将这个元素插入到堆中；如果比堆顶元素小，则不做处理，继续遍历数组。这样等数组中的数据都遍历完之后，堆中的数据就是前 K 大数据了。遍历数组需要 O(n) 的时间复杂度，一次堆化操作需要 O(logK) 的时间复杂度，所以最坏情况下，n 个元素都入堆一次，时间复杂度就是 O(nlogK)。
- 针对动态数据求得 Top K 就是实时 Top K。怎么理解呢？我们可以一直都维护一个 K 大小的小顶堆，当有数据被添加到集合中时，我们就拿它与堆顶的元素对比。如果比堆顶元素大，我们就把堆顶元素删除，并且将这个元素插入到堆中；如果比堆顶元素小，则不做处理。这样，无论任何时候需要查询当前的前 K 大数据，我们都可以立刻返回给他。

利用堆求中位数

- 中位数，顾名思义，就是处在中间位置的那个数。如果数据的个数是奇数，把数据从小到大排列，那第 n/2 个数据就是中位数（注意：假设数据是从 0 开始编号的）；如果数据的个数是偶数的话，那处于中间位置的数据有两个，第 n/2-1​ 个和第 n/2 个数据，这个时候，取两个数据的平均值做为中位数。
- 对于一组静态数据，中位数是固定的，我们可以先排序。每次询问中位数的时候，我们直接返回这个固定的值就好了。所以，尽管排序的代价比较大，但是边际成本会很小。
- 对于动态数据集合，我们需要维护两个堆，一个大顶堆，一个小顶堆。大顶堆中存储前半部分数据，小顶堆中存储后半部分数据，且小顶堆中的数据都大于大顶堆中的数据。大顶堆中的堆顶元素就是我们要找的中位数。如果新加入的数据小于等于大顶堆的堆顶元素，我们就将这个新数据插入到大顶堆；否则，我们就将这个新数据插入到小顶堆。这个时候就有可能出现，两个堆中的数据个数不符合前面约定的情况，我们可以从一个堆中不停地将堆顶元素移动到另一个堆，通过这样的调整，来让两个堆中的数据满足上面的约定。还可以通过不均分的方式来处理一些问题。
- [数据流中的中位数](BinaryTree/get_middle_number_of_stream.cpp)：如何得到一个数据流中的中位数？如果从数据流中读出奇数个数值，那么中位数就是所有数值排序之后位于中间的数值。如果从数据流中读出偶数个数值，那么中位数就是所有数值排序之后中间两个数的平均值。可以在数据的总数目是偶数时把新数据插入最小堆，否则插入最大堆，还要保证最大堆中的所有数据都要大于最小堆中的数据，当数据的总数目是偶数时，按照前面的分配规则会把新的数据插入最小堆，如果此时这个新的数据比最大堆中的一些数据要小，可以先把这个新的数据插入最大堆，接着把最大堆中最大的数字拿出来插入最小堆，由于最终插入最小堆的数字是原最大堆中最大的数字，这样就保证了最小堆中所有数字都大于最大堆中的数字。

### 测试用例

- [完全二叉树](Google_tests/BinaryTree/CompleteBinaryTreeTest.cpp)，[完全二叉搜索树](Google_tests/BinaryTree/CompleteBSTTest.cpp)
- [非完全二叉树](Google_tests/BinaryTree/NonCompleteBinaryTreeTest.cpp)，[非完全二叉搜索树](Google_tests/BinaryTree/NonCompleteBSTTest.cpp)
- [只有左节点的二叉树](Google_tests/BinaryTree/OnlyLeftNodeBinaryTreeTest.cpp)，[只有左节点的二叉搜索树](Google_tests/BinaryTree/OnlyLeftNodeBSTTest.cpp)
- [只有右节点的二叉树](Google_tests/BinaryTree/OnlyRightNodeBinaryTreeTest.cpp)，[只有右节点的二叉搜索树](Google_tests/BinaryTree/OnlyRightNodeBSTTest.cpp)
- [只有一个节点的二叉树](Google_tests/BinaryTree/OneNodeBinaryTreeTest.cpp)
- [空的二叉树](Google_tests/BinaryTree/EmptyBinaryTreeTest.cpp)

### 三种基本遍历

掌握前序遍历、中序遍历、后序遍历，命名的方式是操作子树根节点相对于遍历其左右子树的顺序。二叉树遍历的时间复杂度是 O(n)。

- [前序遍历](BinaryTree/binary_tree.cpp)
- [中序遍历](BinaryTree/binary_tree.cpp)
- [后序遍历](BinaryTree/binary_tree.cpp)

### 前序遍历结果的特点

第一个数字是树的根节点的值，后面的数字可以分为两部分，第一部分是左子树节点的值，如果是 BST，它们都比根节点的值小，
第一部分是右子树节点的值，如果是 BST，它们都比根节点的值大。

- [输入二叉树的前序遍历和中序遍历的结果，结果中不含重复数字，重建此二叉树](BinaryTree/construct_binary_tree_with_preorder_inorder_walk_result.cpp)
- [输入两棵二叉树 A 和 B，判断 B 是不是 A 的子结构](BinaryTree/binary_tree_contain_sub_tree.cpp)
- [二叉树的镜像](BinaryTree/mirror_binary_tree.cpp)
- [对称的二叉树](BinaryTree/binary_tree_is_symmetrical.cpp)
- [序列化和反序列化二叉树](BinaryTree/serialize_binary_tree.cpp)

### 中序遍历结果的特点

根节点的值在中间，剩下的数字可以分为前后两部分，前面部分是左子树节点的值，如果是 BST，它们都比根节点的值小，后面部分是右子树节点的值，如果是 BST，它们都比根节点的值大。

- [查找二叉搜索树的第 k 大节点](BinaryTree/find_kth_node_in_bst.cpp)
- [输入一个棵二叉搜索树，将其转换成一个排序的双向链表，不能创建任何新的节点，只能调整树中节点指针的指向](BinaryTree/bst_to_link_list.cpp)
- [找出二叉树中一个节点的中序遍历序列的下一个节点，树中的节点还有一个指向父节点的指针](BinaryTree/get_binary_tree_inorder_walk_next.cpp)

### 后序遍历结果的特点

最后一个数字是数的根节点的值，前面的数字可以分为两部分，第一部分是左子树节点的值，如果是 BST，它们都比根节点的值小，
第一部分是右子树节点的值，如果是 BST，它们都比根节点的值大。

- [输入一个整数数组，判断该数组是不是某二叉搜索树的后序遍历结果](BinaryTree/is_postorder_sequence_of_bst.cpp)
- [二叉树的深度](BinaryTree/binary_tree_depth.cpp)
- [平衡二叉树，任意节点的左、右子树的深度相差不超过 1](BinaryTree/binary_tree_is_balance.cpp)

### 利用队列或栈作为树的辅助

- [从上到下打印二叉树](BinaryTree/top_to_bottom_binary_tree_walk.cpp)
- [分行从上到下打印二叉树](BinaryTree/top_to_bottom_binary_tree_walk.cpp)
- [之字形从上到下打印二叉树](BinaryTree/top_to_bottom_binary_tree_walk.cpp)
- [输入一颗二叉树和一个整数，打印出二叉树中节点值的和为输入整数的所有路径](BinaryTree/find_summary_path_in_binary_tree.cpp)

### 树中两个节点的最低公共祖先

- 二叉搜索树：从树的根节点开始和两个输入的节点进行比较，如果当前节点的值比两个节点的值都大，那么最低的共同父节点一定在当前节点的左子树中，于是下一步遍历当前节点的左子节点，如果当前节点的值比两个节点的值都小，那么最低的共同父节点一定在当前节点的右子树中，于是下一步遍历当前节点的右子节点，这样，在树中从上到下找到的第一个在两个输入节点的值之间的节点就是最低的公共祖先。
- 节点带有父节点的树：从树的每个叶节点开始都有一个由指针 parent 串起来的链表，这些链表的尾指针都是树的根节点，两个节点位于两个链表上，它们的最低公共祖先刚好就是这两个链表的一个公共节点。
- [普通树：用两个链表分别保存从根节点到输入的两个节点的路径，把问题转换成两个链表的最后公共节点。](Tree/get_tree_last_common_parent.cpp)

## 🗺 图 Graph

### 图的定义

- 图中的元素我们就叫做顶点（vertex）。图中的一个顶点可以与任意其他顶点建立连接关系，这种建立的关系叫做边（edge）。顶点的度（degree），就是跟顶点相连接的边的条数。
- 边有方向的图叫做 "有向图"。边没有方向的图就叫做 "无向图"。在有向图中，把度分为入度（In-degree）和出度（Out-degree）。
- 在带权图（weighted graph）中，每条边都有一个权重（weight）。

### 图的存储方法

#### 邻接矩阵存储方法

邻接矩阵（Adjacency Matrix）的底层依赖一个二维数组。对于无向图来说，如果顶点 i 与顶点 j 之间有边，我们就将 A[i][j] 和 A[j][i] 标记为 1；对于有向图来说，如果顶点 i 到顶点 j 之间，有一条箭头从顶点 i 指向顶点 j 的边，那我们就将 A[i][j] 标记为 1。同理，如果有一条箭头从顶点 j 指向顶点 i 的边，我们就将 A[j][i] 标记为 1。对于带权图，数组中就存储相应的权重。

会浪费存储空间，好处是方便计算，可以将很多图的运算转换成矩阵之间的运算。

#### 邻接表存储方法

邻接表（Adjacency List）中每个顶点对应一条链表，链表中存储的是与这个顶点相连接的其他顶点。一个有向图的邻接表存储方式，每个顶点对应的链表里面，存储的是指向的顶点。对于无向图来说，也是类似的，不过，每个顶点的链表中存储的，是跟这个顶点有边相连的顶点。

邻接矩阵存储起来比较浪费空间，但是使用起来比较节省时间。相反，邻接表存储起来比较节省空间，但是使用起来就比较耗时间。邻接表长得很像散列，在基于链表法解决冲突的散列表中，如果链过长，为了提高查找效率，我们可以将链表换成其他更加高效的数据结构。

### 广度优先搜索 Breadth-First-Search BFS

既可以用在无向图，也可以用在有向图上。地毯式层层推进，即先查找离起始顶点最近的，然后是次近的，依次往外搜索，[广度优先搜索需要借助队列来实现](Graph/graph.cpp)，遍历得到的路径就是，起始顶点到终止顶点的最短路径。时间复杂度都是 O(E)，空间复杂度是 O(V)。

### 深度优先搜索 Depth-First-Search DFS

既可以用在无向图，也可以用在有向图上。最直观的例子就是 "走迷宫"，假设你站在迷宫的某个岔路口，然后想找到出口，你随意选择一个岔路口来走，走着走着发现走不通的时候，你就回退到上一个岔路口，重新选择一条路继续走，直到最终找到出口。[深度优先搜索借助栈来实现](Graph/graph.cpp)，找出来的路径，并不一定是最短路径。深度优先搜索用的是回溯思想，非常适合用递归实现。时间复杂度都是 O(E)，空间复杂度是 O(V)。

## 🔤 字符串

### 字符串匹配

#### BF 算法

BF 是 Brute Force 的缩写，中文叫作暴力匹配算法，也叫朴素匹配算法。在字符串 A 中查找字符串 B，那字符串 A 就是主串，字符串 B 就是模式串。我们在主串中，检查起始位置分别是 0、1、2…n-m 且长度为 m 的 n-m+1 个子串，看有没有跟模式串匹配的。这种算法的最坏情况时间复杂度是 O(n*m)。

#### RK 算法

RK 算法的全称叫 Rabin-Karp 算法，整个 RK 算法包含两部分：

- 第一部分，计算子串哈希值，比如要处理的字符串只包含 a～z 这 26 个小写字母，那我们就用二十六进制来表示一个字符串，我们把 a～z 这 26 个字符映射到 0～25 这 26 个数字，a 就表示 0，b 就表示 1，以此类推，z 表示 25，只需要扫描一遍主串就能计算出所有子串的哈希值了，所以这部分的时间复杂度是 O(n)。
- 第二部分，模式串哈希值与每个子串哈希值之间的比较的时间复杂度是 O(1)，总共需要比较 n-m+1 个子串的哈希值，所以，这部分的时间复杂度也是 O(n)。

所以，RK 算法整体的时间复杂度就是 O(n)。

模式串很长，相应的主串中的子串也会很长，通过上面的哈希算法计算得到的哈希值就可能很大，如果超过了计算机中整型数据可以表示的范围，那该如何解决呢？设计有散列冲突的哈希算法，使产生的哈希值的数据范围相对要小很多，当我们发现一个子串的哈希值跟模式串的哈希值相等的时候，我们只需要再对比一下子串和模式串本身就好了，当然，如果子串的哈希值与模式串的哈希值不相等，那对应的子串和模式串肯定也是不匹配的，就不需要比对子串和模式串本身了。

#### BM 算法

在模式串与主串匹配的过程中，当模式串和主串某个字符不匹配的时候，能够跳过一些肯定不会匹配的情况，将模式串往后多滑动几位：

- [坏字符规则（bad character rule）](String/string_match.cpp)：从模式串的末尾往前倒着匹配，当发现某个字符没法匹配的时候，把这个没有匹配的字符叫作坏字符（主串中的字符），当发生不匹配的时候，把坏字符对应的模式串中的字符下标记作 si，如果坏字符在模式串中存在，我们把这个坏字符在模式串中的下标记作 xi。如果不存在，我们把 xi 记作 -1。那模式串往后移动的位数就等于 si-xi。（注意，我这里说的下标，都是字符在模式串的下标）。不过，单纯使用坏字符规则还是不够的，因为根据 si-xi 计算出来的移动位数，比如主串是 aaaaaaaaaaaaaaaa，模式串是 baaa，不会向后滑动模式串。在
- [好后缀规则（good suffix shift）](String/string_match.cpp)：从模式串的末尾往前倒着匹配，当发现某个字符没法匹配的时候，但有一些后缀是匹配的，把已经匹配的字符叫作好后缀（主串中的字符），拿好后缀在模式串中查找另一个相匹配的子串，如果找到了就将模式串滑动到两者对齐的位置，如果没有，从好后缀的后缀子串中，找一个最长的并且能跟模式串的前缀子串匹配的，如果找到了就将模式串滑动到两者对齐的位置，如果没有，才将模式串滑动到主串当前比较位置的后面。

因为坏字符规则的实现比较耗内存，为了节省内存，我们可以只用好后缀规则来实现 BM 算法，不过，单纯使用好后缀规则的 BM 算法效率就会下降一些了。

#### KMP 算法

KMP 算法的全称是 Knuth Morris Pratt 算法。

在模式串和主串正序匹配的过程中，把不能匹配的那个字符仍然叫作坏字符，把已经匹配的那段字符串叫作[好前缀](String/string_match.cpp)。当遇到坏字符的时候，如果有好前缀，我们就要把模式串往后滑动，在滑动的过程中，只要模式串和好前缀有上下重合，前面几个字符的比较，就相当于拿好前缀的后缀子串，跟模式串的前缀子串在比较，这就等同于拿好前缀本身，在它的后缀子串中，查找可以跟好前缀的前缀子串匹配的最长的那个。[只需要通过模式串本身就能求解好前缀的最长可匹配前缀子串和后缀子串](String/string_match.cpp)。

KMP 算法的时间复杂度就是 O(m+n)。

#### Trie 树

Trie 树，也叫 "字典树"，它是一种专门处理字符串匹配的数据结构，用来解决在一组字符串集合中快速查找某个字符串的问题。Trie 树的本质，就是利用字符串之间的公共前缀，将重复的前缀合并在一起。

根节点不包含任何信息，每个节点表示一个字符串中的字符，从根节点到红色节点的一条路径表示一个字符串（注意：红色节点并不都是叶子节点）。Trie 树是一个多叉树，利用基于数组的字符散列表做为每个节点，数组的下标就是子节点表示的字符的 ASCII 码减去 "a"，数组的值就是指向子节点的指针。构建 Trie 树的过程，需要扫描所有的字符串，时间复杂度是 O(n)，n 表示所有字符串的长度和。每次查询时，如果要查询的字符串长度是 k，那我们只需要比对大约 k 个节点，就能完成查询操作，查找字符串的时间复杂度是 O(k)。

Trie 树是非常耗内存的，用的是一种空间换时间的思路，可以稍微牺牲一点查询的效率，将每个节点中的数组换成其他数据结构，来存储一个节点的子节点指针，假设我们用有序数组，数组中的指针按照所指向的子节点中的字符的大小顺序排列。查询的时候，我们可以通过二分查找的方法，快速查找到某个字符应该匹配的子节点的指针。但是，在往 Trie 树中插入一个字符串的时候，我们为了维护数组中数据的有序性，就会稍微慢了点。

Trie 树只是不适合精确匹配查找，这种问题更适合用散列表或者红黑树来解决。Trie 树比较适合的是查找前缀匹配的字符串。

#### AC 自动机

单模式串匹配算法，是在一个模式串和一个主串之间进行匹配，也就是说，在一个主串中查找一个模式串，有 BF 算法、RK 算法、BM 算法、KMP 算法。多模式串匹配算法，就是在多个模式串和一个主串之间做匹配，也就是说，在一个主串中查找多个模式串，有 Trie 树、有 AC 自动机。

那如何用 Trie 树实现敏感词过滤功能呢？我们可以对敏感词字典进行预处理，构建成 Trie 树结构。这个预处理的操作只需要做一次，如果敏感词字典动态更新了，比如删除、添加了一个敏感词，那我们只需要动态更新一下 Trie 树就可以了。当用户输入一个文本内容后，我们把用户输入的内容作为主串，从第一个字符（假设是字符 C）开始，在 Trie 树中匹配。当匹配到 Trie 树的叶子节点，或者中途遇到不匹配字符的时候，我们将主串的开始匹配位置后移一位，也就是从字符 C 的下一个字符开始，重新在 Trie 树中匹配。

AC 自动机算法，全称是 Aho-Corasick 算法。其实，Trie 树跟 AC 自动机之间的关系，就像单串匹配中朴素的串匹配算法，跟 KMP 算法之间的关系一样，只不过前者针对的是多模式串而已。所以，AC 自动机实际上就是在 Trie 树之上，加了类似 KMP 的 next 数组，只不过此处的 next 数组是构建在树上罢了。

### 大数问题，用字符串表示数字

- [打印从 1 到最大的 n 位数：输入数字 n，按顺序打印出从 1 到最大的 n 位十进制数，比如输入 3，则打印出 1、2、3 一直到最大的 3 位数 999。](String/print_one_to_max_of_n_digits.cpp)
- [表示数值的字符串：实现一个函数用来判断字符串是否表示数值（包括整数和小数）。例如，字符串 "+100"、"5e2"、"-123"、"3.1416" 及 "-1E-16" 都表示数值，但 "12e"、"1a3.14"、"1.2.3"、"+-5" 及 "12e+5.4" 都不是。表示数值的字符串遵循模式 A\[.\[B\]\]\[e|EC\] 或者.B\[e|EC\]，其中 A 为数值的整数部分，B 紧跟着小数点为数值的小数部分，C 紧跟着 'e' 或者 'E' 为数值的指数部分。在小数里可能没有数值的整数部分。例如，小数 .123 等于 0.123。因此 A 部分不是必需的。如果一个数没有整数部分，那么它的小数部分不能为空。上述 A 和 C 都是可能以 '+' 或者 '-' 开头的 0～9 的数位串；B 也是 0～9 的数位串，但前面不能有正负号。](String/is_string_represent_number.cpp
)

### 其他题目

- [字符串转数字: 10 进制，如 "1234" => 1234](String/string_to_int.cpp)
- [字符串转数字: 26 进制的大写字母，如 A=1,B=2,C=3,...,Z=26,AA=27,AB=28](String/string_to_int.cpp)
- [输入一个英文句子，翻转句子中单词的顺序，但单词内字符的顺序不变。为简单起见，标点符号和普通字母一样处理。例如输入字符串 "I am a student."，则输出 "student. a am I"。](String/reverse_string.cpp)
- [字符串的左旋转操作是把字符串前面的若干个字符转移到字符串的尾部，比如，输入字符串 "abcdefg" 和数字 2，该函数将返回左旋转两位得到的结果 "cdefgab"。](String/reverse_string.cpp)
- [替换空格](String/replace_string_space.cpp)：请实现一个函数，把字符串中的每个空格替换成 "%20"。例如，入 "We are happy."，则输出 "We%20are%20happy."。在合并两个数组（包括字符串）时，如果从前往后复制每个数字（或字符）则需要重复移动数字（或字符）多次，那么我们可以考虑从后往前复制，这样就能减少移动的次数，从而提高效率。
- [正则表达式匹配](String/simple_regular_expression.cpp)：请实现一个函数用来匹配包含 '.' 和 '\*' 的正则表达式。模式中的字符 '.' 表示任意一个字符，而 '\*' 表示它前面的字符可以出现任意次（含 0 次）。在本题中，匹配是指字符串的所有字符匹配整个模式。例如，字符串 "aaa" 与模式 "a.a" 和 "ab\*ac\*a" 匹配，但与 "aa.a" 和 "ab\*a" 均不匹配。
- [字符串的排列](String/string_permutation.cpp)：输入一个字符串，打印出该字符串中字符的所有排列。例如，输入字符串 abc，则打印出由字符 a、b、c 所能排列出来的所有字符串 abc、acb、bac、bca、cab 和 cba。如果题目是按照一定要求摆放若干个数字，则可以先求出这些数字的所有排列，然后一一判断每个排列是不是满足题目给定的要求。
- [把数字翻译成字符串](String/translate_number_to_string.cpp)：给定一个数字，我们按照如下规则把它翻译为字符串：0 翻译成 "a"，1 翻译成 "b"，...，11 翻译成 "l"，...，25 翻译成 "z"。一个数字可能有多个翻译。例如，12258 有 5 种不同的翻译，分别是 "bccfi"、"bwfi"、"bczi"、"mcfi" 和 "mzi"。请编程实现一个函数，用来计算一个数字有多少种不同的翻译方法。我们以 12258 为例分析如何从数字的第一位开始一步步计算不同翻译方法的数目。我们有两种不同的选择来翻译第一位数字 1。第一种选择是数字 1 单独翻译成 "b"，后面剩下数字 2258；第二种选择是 1 和紧挨着的 2 一起翻译成 "m"，后面剩下数字 258。定义函数 f(i) 表示从第 i 位数字开始的不同翻译的数目，那么 f(i) = f(i+1) + g(i，i+1)*f(i+2)。当第 i 位和第 i+1 位两位数字拼接起来的数字在 10~25 的范围内时，函数 g(i，i+1) 的值为 1，否则为 0。

## 0️⃣ 位运算 Bitwise Operation

| Operator | Symbol | Form | Operation |
| ---- | ---- | ---- | ---- |
| left shift | << | x << y | all bits in x shifted left y bits |
| right shift | >> | x >> y | all bits in x shifted right y bits |
| bitwise NOT | ~ | ~x | all bits in x flipped |
| bitwise AND | & | x & y | each bit in x AND each bit in y |
| bitwise OR | &#124; | x &#124; y | each bit in x OR each bit in y |
| bitwise XOR | ^ | x ^ y | each bit in x XOR each bit in y |

异或：

    0 ^ 0 = 0
    1 ^ 0 = 1
    0 ^ 1 = 1
    1 ^ 1 = 0

左移运算符 m << n 把 m 左移 n 位，最左边的 n 位被丢弃，同时在最右边补上 n 个 0：

    00001010 << 2 = 00101000
    10001010 << 3 = 01010000

右移运算符 m >> n 把 m 右移 n 位，最右边的 n 位被丢弃。如果数字是一个无符号数值，则用 0 填补最左边的 n 位；如果数字是一个有符号数值，则用数字的符号位填补最左边的 n 位，也就是如果数字原先是正数，则填补 0，如果数字原先是负数，则填补 1：

    00001010 >> 2 = 00000010
    10001010 >> 3 = 11110001

### 理解位运算的特点

- 避免使用右移可能导致的死循环。
- 重要的技巧，把一个整数减去 1 之后再和原来的整数做位与运算，得到的结果相当于把整数的二进制表示中最右边的 1 变成 0。
- [输入一个整数，输出该数二进制表示中 1 的个数。](Bitwise/count_one_of_number.cpp)
- [一个整型数组里除两个数字之外，其他数字都出现了两次，找出这两个数字，要求时间复杂度是 O(n)，空间复杂度是 O(1)，成对出现的数字在异或中全部抵消了，两个数字不同，异或的结果不为 0，结果数字的二进制表示中至少有一位为 1，在结果数字中找第一个为 1 的位的位置，记为第 n 位，以第 n 位是不是 1 把原数组中的数字分成两个子数组，分别找出只出现一次的数字。](Bitwise/find_numbers_appear_once.cpp)
- [一个整型数组中除一个数字只出现一次之外，其他数字都出现了三次，找出这个数字，把数组中所有数字的二进制表示的每一位都加起来，如果某一位的和能被 3 整除，那么那个只出现一次的数字二进制表示中对应的那一位是 0，否则就是 1。](Bitwise/find_numbers_appear_once.cpp)
- [不用加减乘除做加法，求两个整数之和，分三步走，第一步，不考虑进位对每一位相加，0 加 0、1 加 1 的结果都是 0，0 加 1、1 加 0 的结果都是 1，这和异或的结果是一样的；第二步，考虑进位，对 0 加 0、0 加 1、1 加 0，都不会产生进位，只有 1 加 1，会向前产生一个进位，这就是两个数先做位与运算，再向左移动一位；第三步，把前两个步骤的结果相加，依然是重复前两步，直到不产生进位为止。](Bitwise/add_with_bitwise.cpp)
- 不使用新的变量，交换两个变量的值，`a = a ^ b; b = a ^ b; a = a ^ b`。

## 🧮 其他

- [数值的整数次方：实现函数 double Power(double base, int exponent)，求 base 的 exponent 次方，不得使用库函数，不需要考虑大数问题。](Other/power.cpp)

用空间换时间的设计思想。当内存空间充足的时候，如果我们更加追求代码的执行速度，我们就可以选择空间复杂度相对较高、但时间复杂度相对很低的算法或者数据结构。相反，如果内存比较紧缺，比如代码跑在手机或者单片机上，这个时候，就要反过来用时间换空间的设计思路。

- [整数数组中查找最长递增序列](time_efficiency.cpp#L13)
