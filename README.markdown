## ⏳ 复杂度分析

### 时间复杂度分析

大 O 时间复杂度实际上并不具体表示代码真正的执行时间，而是表示代码执行时间随数据规模增长的变化趋势，所以，也叫作渐进时间复杂度（asymptotic time complexity），简称时间复杂度。

分析的实用方法：

1. 只关注循环执行次数最多的一段代码
2. 加法法则：总复杂度等于量级最大的那段代码的复杂度
3. 乘法法则：嵌套代码的复杂度等于嵌套内外代码复杂度的乘积
4. 递推公式分析法
5. 递归树分析法

### 常见的时间复杂度

![Big O](http://danthought.com/big-o.png)

- 多项式量级
    - 常量阶 O(1)
    - 对数阶 O(logn)
    - 线性阶 O(n)
    - 线性对数阶 O(nlogn)
    - 平方阶 O(n2) 立方阶 O(n3)
- 非多项式量级 当数据规模 n 越来越大时，非多项式量级算法的执行时间会急剧增加，求解问题的执行时间会无限增长。
    - 指数阶 O(2n)
    - 阶乘阶 O(n!)

### 空间复杂度分析

空间复杂度全称就是渐进空间复杂度（asymptotic space complexity），表示算法的存储空间与数据规模之间的增长关系。注意说空间复杂度的时候，是指除了原本的数据存储空间外，算法运行还需要额外的存储空间。

### 最好情况时间复杂度

最好情况时间复杂度（best case time complexity）就是，在最理想的情况下，执行这段代码的时间复杂度。

### 最坏情况时间复杂度

最坏情况时间复杂度（worst case time complexity）就是，在最糟糕的情况下，执行这段代码的时间复杂度。

### 平均情况时间复杂度

平均情况时间复杂度（average case time complexity）把每种情况发生的概率也考虑进去，每种情况操作的耗时乘以其发生的概率，这个值就是概率论中的加权平均值，也叫作期望值，所以平均时间复杂度的全称应该叫加权平均时间复杂度或者期望时间复杂度。

### 均摊时间复杂度

均摊时间复杂度（amortized time complexity）就是一种特殊的平均时间复杂度，对一个数据结构进行一组连续操作中，大部分情况下时间复杂度都很低，只有个别情况下时间复杂度比较高，而且这些操作之间存在前后连贯的时序关系，这个时候，我们就可以将这一组操作放在一块儿分析，看是否能将较高时间复杂度那次操作的耗时，平摊到其他那些时间复杂度比较低的操作上。而且，在能够应用均摊时间复杂度分析的场合，一般均摊时间复杂度就等于最好情况时间复杂度。

## 🔢 数组 Array

### 定义

数组（Array）是一种线性表数据结构。它用一组连续的内存空间，来存储一组具有相同类型的数据。

第一是线性表（Linear List）。顾名思义，线性表就是数据排成像一条线一样的结构。每个线性表上的数据最多只有前和后两个方向。其实除了数组，链表、队列、栈等也是线性表结构。

第二个是连续的内存空间和相同类型的数据。正是因为这两个限制，它才有了一个堪称“杀手锏”的特性：“随机访问”。但有利就有弊，这两个限制也让数组的很多操作变得非常低效，比如要想在数组中删除、插入一个数据，为了保证连续性，就需要做大量的数据搬移工作。

### 低效的插入

假设数组的长度为 n，现在，如果我们需要将一个数据插入到数组中的第 k 个位置。为了把第 k 个位置腾出来，给新来的数据，我们需要将第 k～n 这部分的元素都顺序地往后挪一位。平均情况时间复杂度为 (1 + 2 + … n) / n = O(n)。

如果数组中存储的数据并没有任何规律，数组只是被当作一个存储数据的集合。在这种情况下，如果要将某个数据插入到第 k 个位置，为了避免大规模的数据搬移，我们还有一个简单的办法就是，直接将第 k 位的数据搬移到数组元素的最后，把新的元素直接放入第 k 个位置。利用这种处理技巧，在特定场景下，在第 k 个位置插入一个元素的时间复杂度就会降为 O(1)。

### 低效的删除

跟插入数据类似，如果我们要删除第 k 个位置的数据，为了内存的连续性，也需要搬移数据，不然中间就会出现空洞，内存就不连续了。和插入类似，如果删除数组末尾的数据，则最好情况时间复杂度为 O(1)；如果删除开头的数据，则最坏情况时间复杂度为 O(n)；平均情况时间复杂度也为 O(n)。

每次的删除操作并不是真正地搬移数据，只是记录数据已经被删除。当数组没有更多空间存储数据时，我们再触发执行一次真正的删除操作，这样就大大减少了删除操作导致的数据搬移。

### 数组中重复的数字

- 长度为 n 的数组里的所有数字都在 0～n-1 的范围内。数组中某些数字是重复的，但不知道有几个数字重复了，也不知道每个数字重复了几次，找出数组中任意一个重复的数字。例如，如果输入长度为 7 的数组 { 2，3，1，0，2，5，3 }，那么对应的输出是重复的数字 2 或者 3。
    - 排序
    - 利用哈希表来解决这个问题。从头到尾按顺序扫描数组的每个数字，每扫描到一个数字的时候，都可以用 O(1) 的时间来判断哈希表里是否已经包含了该数字。如果哈希表里还没有这个数字，就把它加入哈希表。如果哈希表里已经存在该数字，就找到一个重复的数字。这个算法的时间杂度是 O(n)，但它提高时间效率是以一个大小为 O(m) 的哈希表为代价的。
    - [从头到尾依次扫描这个数组中的每个数字。扫描到下标为 i 的数字时，首先比较这个数字（用 m 表示）是不是等于 i。如果是，则接着扫描下一个数字;如果不是，则再拿它和第 m 个数字进行比较。如果它和第 m 个数字相等，就找到了一个重复的数字（该数字在下标为 i 和 m 的位置都出现了）;如果它和第 m 个数字不相等，就把第 i 个数字和第 m 个数字交换，把 m 放到属于它的位置。接下来再重复这个比较、交换的过程，直到我们发现一个重复的数字。](Array/find_duplicate_number_of_array.cpp)
- 在一个长度为 n+1 的数组里的所有数字都在 1～n 的范围内，所以数组中至少有一个数字是重复的。请找出数组中任意一个重复的数字，但不能修改输入的数组。例如，如果输入长度为 8 的数组 { 2，3，5，4，3，2，6，7 }，那么对应的输出是重复的数字 2 或者 3。 
    - 哈希表
    - [把从 1～n 的数字从中间的数字 m 分为两部分，前面一半为 1～m，后面一半为 m+1～n。如果 1～m 的数字的数目超过 m，那么这一半的区间一定包含重复的数字;否则，另一半 m+1～n 的区间里一定包含重复的数字。我们可以继续把包含重复数字的区间一分为二，直到找到一个重复的数字。这个过程和二分查找算法很类似，只是多了一步统计区间里数字的数目。 ](Array/find_duplicate_number_of_array.cpp)
- [在一个二维数组中，每一行都按照从左到右递增的顺序，每一列都按照从上到下递增的顺序排序。请完成一个函数，输入这样的一个二维数组和一个整数，判断数组中是否含有该整数。 首先选取数组中右上角的数字，如果该数字等于要查找的数字，则查找过程结束；如果该数字大要查找的数字，则剔除这个数字所在的列；如果该数字小于要查找的数字，则剔除这个数字所在的行。也就是说，如果要查找的数字不在数组的右上角，则每一次都在数组的查找范围中剔除一行或者一列，这样每一步都可以缩小查找的范围，直到找到要查找的数字，或者查找范围为空。](Array/find_number_of_matrix.cpp)
- [输入一个整数数组，实现一个函数来调整该数组中数字的顺序得所有奇数位于数组的前半部分，所有偶数位于数组的后半部分。把数组中的数按照大小分为两部分，所有负数都在非负数的前面。把数组中的数分为两部分，能被 3 整除的数都在不能被 3 整除的数的前面。参考 Partition](Array/divide_array.cpp)

## 🔗 链表 Link List

### 定义

数组需要一块连续的内存空间来存储，对内存的要求比较高，而链表恰恰相反，它并不需要一块连续的内存空间，它通过“指针”将一组零散的内存块串联起来使用。

数组简单易用，在实现上使用的是连续的内存空间，可以借助 CPU 的缓存机制，预读数组中的数据，所以访问效率更高。而链表在内存中并不是连续存储，所以对 CPU 缓存不友好，没办法有效预读。

除此之外，如果你的代码对内存的使用非常苛刻，那数组就更适合你。因为链表中的每个结点都需要消耗额外的存储空间去存储一份指向下一个结点的指针，所以内存消耗会翻倍。而且，对链表进行频繁的插入、删除操作，还会导致频繁的内存申请和释放，容易造成内存碎片，如果是 Java 语言，就有可能会导致频繁的 GC（Garbage Collection，垃圾回收）。

### 测试用例

- [链表包含多个结点](Google_tests/LinkList/NormalLinkListTest.cpp)
- [链表只包含两个结点](Google_tests/LinkList/TwoNodesLinkListTest.cpp)
- [链表只包含一个结点](Google_tests/LinkList/OneNodeLinkListTest.cpp)
- [链表为空](Google_tests/LinkList/EmptyLinkListTest.cpp)

### 基本的增删查

- 对于单向链表，增加和删除都要先找到前驱节点，只能一个个地查找，所以为 O(n)。
- 针对链表的插入、删除操作，需要对插入第一个结点和删除最后一个结点的情况进行特殊处理。如果我们引入哨兵结点，在任何时候，不管链表是不是空，head 指针都会一直指向这个哨兵结点。我们也把这种有哨兵结点的链表叫带头链表。相反，没有哨兵结点的链表就叫作不带头链表。
- [某个指定结点前面插入一个结点：双向链表可以在 O(1) 时间复杂度搞定，而单向链表需要 O(n) 的时间复杂度。](LinkList/link_list_append_node.cpp)
- [删除给定指针指向的结点：因为双向链表中的结点已经保存了前驱结点的指针，不需要像单链表那样遍历。所以，单链表删除操作需要 O(n) 的时间复杂度，而双向链表只需要在 O(1) 的时间复杂度内就搞定了。](LinkList/link_list_remove_node.cpp)

### 增删时，考虑被操作的节点在头部、中间和尾部的情况

- [两个有序（从小到大）单链表，构造一条新链表，包含同时出现在两个链表的节点](LinkList/intersect_two_sorted_link_list.cpp)
- [给定的一个节点指针，在 O(1) 时间内，删除链表节点](LinkList/link_list_remove_node.cpp)
- [在一个排序的链表中删除重复节点](LinkList/link_list_remove_node.cpp)
- [反转链表](LinkList/reverse_link_list.cpp)
- [合并两个排序的链表](LinkList/merge_link_list.cpp)

### 查询时，考虑多个指向不同位置的指针：快慢指针，相隔一定距离的指针

- [从尾到头打印链表](LinkList/print_link_list_reverse.cpp)
- [从链表中找出中间的节点](LinkList/find_middle_node_of_link_list.cpp)
- [从链表中找出倒数第 k 个节点，如 1、2、3、4、5、6，倒数第 3 个节点是 4，删除链表倒数第 n 个结点思路和这个相同](LinkList/find_kth_to_tail_of_link_list.cpp)
- [从链表中找出环的入口节点（含链表中环的检测的步骤）](LinkList/entry_node_of_loop_link_list.cpp)
- [两个链表的第一个公共节点](LinkList/find_first_common_node_of_link_list.cpp)
- [单向链表存储的字符串，判断其是否是回文字符串](LinkList/check_palindromic_string_in_link_list.cpp)

### 链表来实现缓存淘汰策略

- [先进先出策略 FIFO（First In，First Out）](LinkList/find_node_of_cache_in_link_list.cpp)：链表实现的队列；访问数据时，已经缓存的数据，直接返回；没有缓存的数据，缓存未满，新数据直接添加到链表的尾部；缓存已经满，则删除链表头节点，新数据再添加到链表的尾部。
- [最少使用策略 LFU（Least Frequently Used）](LinkList/find_node_of_cache_in_link_list.cpp)：链表按访问次数排序；访问数据时，已经缓存的数据，次数加一，再排序；没有缓存的数据，缓存未满，新数据直接添加到链表的尾部；缓存已经满，则删除链表尾节点，新数据再添加到链表的尾部。
- [最近最少使用策略 LRU（Least Recently Used）](LinkList/find_node_of_cache_in_link_list.cpp)：链表按最近访问时间排序；访问数据时，已经缓存的数据，移动到链表头部；没有缓存的数据，缓存未满，新数据直接插入到链表的头部；缓存已经满，则删除链表尾节点，新数据再插入到链表的头部。

## 🚦 栈和队列 Stack and Queue

### 栈的定义

当某个数据集合只涉及在一端插入和删除数据，并且满足后进先出、先进后出的特性，我们就应该首选“栈”这种数据结构。

### 栈的应用

- 栈在函数调用中的应用：操作系统给每个线程分配了一块独立的内存空间，这块内存被组织成“栈”这种结构, 用来存储函数调用时的临时变量。每进入一个函数，就会将临时变量作为一个栈帧入栈，当被调用函数执行完成，返回之后，将这个函数对应的栈帧出栈。
- 栈在表达式求值中的应用：比如：34+13*9+44-12/3。对于这个四则运算，编译器就是通过两个栈来实现的。其中一个保存操作数的栈，另一个是保存运算符的栈。我们从左向右遍历表达式，当遇到数字，我们就直接压入操作数栈；当遇到运算符，就与运算符栈的栈顶元素进行比较。如果比运算符栈顶元素的优先级高，就将当前运算符压入栈；如果比运算符栈顶元素的优先级低或者相同，从运算符栈中取栈顶运算符，从操作数栈的栈顶取 2 个操作数，然后进行计算，再把计算完的结果压入操作数栈，继续比较。
- 栈在括号匹配中的应用：{[] ()[{}]} 或 [{()}([])] 等都为合法格式，而 {[}()] 或 [({)] 为不合法的格式。用栈来保存未匹配的左括号，从左到右依次扫描字符串。当扫描到左括号时，则将其压入栈中；当扫描到右括号时，从栈顶取出一个左括号。如果能够匹配，则继续扫描剩下的字符串。如果扫描的过程中，遇到不能配对的右括号，或者栈中没有数据，则说明为非法格式。
- 实现浏览器的前进、后退功能：使用两个栈，X 和 Y，我们把首次浏览的页面依次压入栈 X，当点击后退按钮时，再依次从栈 X 中出栈，并将出栈的数据依次放入栈 Y。当我们点击前进按钮时，我们依次从栈 Y 中取出数据，放入栈 X 中。当栈 X 中没有数据时，那就说明没有页面可以继续后退浏览了。当栈 Y 中没有数据，那就说明没有页面可以点击前进按钮浏览了。

### 队列的定义

入队 enqueue()，放一个数据到队列尾部；出队 dequeue()，从队列头部取一个元素。

### 队列的应用

- 阻塞队列其实就是在队列基础上增加了阻塞操作。简单来说，就是在队列为空的时候，从队头取数据会被阻塞。因为此时还没有数据可取，直到队列中有了数据才能返回；如果队列已经满了，那么插入数据的操作就会被阻塞，直到队列中有空闲位置后再插入数据，然后再返回。线程安全的队列我们叫作并发队列。最简单直接的实现方式是直接在 enqueue()、dequeue() 方法上加锁，但是锁粒度大并发度会比较低，同一时刻仅允许一个存或者取操作。
- 实际上，对于大部分资源有限的场景，当没有空闲资源时，基本上都可以通过“队列”这种数据结构来实现请求排队。

### 数据插入和删除的特性

- [顺序栈：用数组实现的栈](StackAndQueue/stack.cpp) ，注意空和满的情况；支持动态扩容的顺序栈，入栈操作来说，最好情况时间复杂度是 O(1)，最坏情况时间复杂度是 O(n)，均摊时间复杂度是 O(1)
- [链式栈：用链表实现的栈](StackAndQueue/stack.cpp) ，注意空的情况，最好用双向链表
- [包含 min 函数的栈，输出栈中的最小值](StackAndQueue/stack.cpp) 
- [输入两个整数序列，第一个序列表示栈的压入顺序，判断第二个序列是否为该栈的弹出顺序](StackAndQueue/is_pop_order_of_stack.cpp) 
- [顺序队列：用数组实现的队列](StackAndQueue/queue.cpp)，注意空和满的情况，入队操作可能需要数据移动
- [链式队列：用链表实现的队列](StackAndQueue/queue.cpp)，注意空的情况
- [循环队列：用数组实现的循环队列](StackAndQueue/queue.cpp)，注意空和满的情况，空一个位置不存储数据
- [两个栈实现队列](StackAndQueue/queue.cpp) 

## ♻️ 递归和循环 Recursion and Loop

### 递归需要满足的三个条件

- 一个问题的解可以分解为几个子问题的解。
- 这个问题与分解之后的子问题，除了数据规模不同，求解思路完全一样。
- 存在递归终止条件。

### 如何编写递归代码？

- 写递归代码的关键就是找到如何将大问题分解为小问题的规律，并且基于此写出递推公式，然后再推敲终止条件，最后将递推公式和终止条件翻译成代码。

### 递归的优缺点

- 递归实现的代码简洁。
- 递归代码要警惕堆栈溢出，递归层次太深，空间复杂度就高，改为采用循环，或者需要在内存堆上实现栈，手动模拟入栈、出栈过程。
- 递归代码要警惕重复计算，复用之前的计算结果可以提高时间效率。

### 注意重复计算降低时间效率

- [斐波那契数列](RecursionAndLoop/fibonacci.cpp)；青蛙跳台阶：一只青蛙一次可以跳上 1 级台阶，也可以跳上 2 级台阶，该青蛙跳上一个 n 级的台阶总共有多少种跳法。
- [n 个骰子的点数：把 n 个骰子仍在地上，所有骰子朝上一面的点数之和为 s，输入 n，打印出 s 的所有可能的值出现的概率。](RecursionAndLoop/print_dice_probability.cpp)

## 🎰 排序 Sort

### 如何分析一个“排序算法”

- 排序算法的执行效率：最好情况、最坏情况、平均情况时间复杂度，时间复杂度的系数、常数 、低阶，比较次数和交换（或移动）次数。
- 排序算法的内存消耗：原地排序算法，就是特指空间复杂度是 O(1) 的排序算法。
- 排序算法的稳定性：如果待排序的序列中存在值相等的元素，经过排序之后，相等元素之间原有的先后顺序不变。

### 平方阶 O(n2) 的排序算法 

|      | 是原地排序？ | 是否稳定？ | 最好 | 最坏 | 平均 |
| ---- | ---- | ---- | ---- | ---- | ---- |
| [冒泡排序](SortAndFind/bubble_sort.cpp) | 是 | 是 | 线性阶 O(n) | 平方阶 O(n2) | 平方阶 O(n2) |
| [插入排序](SortAndFind/insertion_sort.cpp) | 是 | 是 | 线性阶 O(n) | 平方阶 O(n2) | 平方阶 O(n2) |
| [选择排序](SortAndFind/selection_sort.cpp) | 是 | 否 | 平方阶 O(n2) | 平方阶 O(n2) | 平方阶 O(n2) |

- 选择排序是一种不稳定的排序算法，比如 5，8，5，2，9 这样一组数据，使用选择排序算法来排序的话，第一次找到最小元素 2，与第一个 5 交换位置，那第一个 5 和中间的 5 顺序就变了，所以就不稳定了。
- 冒泡排序和插入排序的比较：冒泡排序的数据交换要比插入排序的数据移动要复杂，冒泡排序需要 3 个赋值操作，而插入排序只需要 1 个；随机生成 10000 个数组，每个数组中包含 200 个数据，然后在我的机器上分别用冒泡和插入排序算法来排序，冒泡排序算法大约 700ms 才能执行完成，而插入排序只需要 100ms 左右就能搞定。

### 线性对数阶 O(nlogn) 的排序算法 

|      | 是原地排序？ | 是否稳定？ | 最好 | 最坏 | 平均 |
| ---- | ---- | ---- | ---- | ---- | ---- |
| [归并排序](SortAndFind/merge_sort.cpp) | 否 | 是 | 线性对数阶 O(nlogn) | 线性对数阶 O(nlogn) | 线性对数阶 O(nlogn) |
| [快速排序](SortAndFind/quick_sort.cpp) | 是 | 否 | 线性对数阶 O(nlogn) | 平方阶 O(n2) | 线性对数阶 O(nlogn) |

- 注意通过数组下标来操作范围。
- 归并排序的空间复杂度是 O(n)。
- 通过合理地选择 pivot 来避免快速排序算法时间复杂度退化到 O(n2)，被分区点分开的两个分区中，数据的数量差不多：
    - 三数取中法：我们从区间的首、尾、中间，分别取出一个数，然后对比大小，取这 3 个数的中间值作为分区点。这样每间隔某个固定的长度，取数据出来比较，将中间值作为分区点的分区算法，肯定要比单纯取某一个数据更好。但是，如果要排序的数组比较大，那“三数取中”可能就不够了，可能要“五数取中”或者“十数取中”。
    - 随机法：随机法就是每次从要排序的区间中，随机选择一个元素作为分区点。这种方法并不能保证每次分区点都选的比较好，但是从概率的角度来看，也不大可能会出现每次分区点都选得很差的情况，所以平均情况下，这样选的分区点是比较好的。时间复杂度退化为最糟糕的 O(n2) 的情况，出现的可能性不大。  
- 归并排序和快速排序的比较：快排和归并用的都是分治思想，归并排序的处理过程是由下到上的，先处理子问题，然后再合并；而快排正好相反，它的处理过程是由上到下的，先分区，然后再处理子问题。

#### 类似快速排序中的 Partition

- [求无序数组中的第 K 大元素：在 O(n) 时间复杂度内求无序数组中的第 K 大元素。比如，4， 2， 5， 12， 3 这样一组数据，第 3 大元素就是 4。](SortAndFind/find_max_kth_in_unsorted_array.cpp)
- [数组中出现次数超过一半的数字：数组中有一个数字出现的次数超过数组长度的一半，请找出过 个数字。例如，输入一个长度为9的数组{1，2，3，2，2，2，5，4，2}。由于数字组中出现了5次，超过数组长度的一半，因此输出2。解法 1 根据 Partition。解法 2，数组中有一个数字出现的次数超过数组长度的一半，也就是说它出现的次数比其他所有数字出现次数的和还要多。因此，我们可以考虑在遍历数组的时候保存两个值∶一个是数组中的一个数字;另一个是次数。当我们遍历到下一个数字的时候，如果下一个数字和我们之前保存的数字相同，则次数加1;如果下一个数字和我们之前保存的数字不同，则次数减1。如果次数为零，那么我们需要份存下一个数字，并把次数设为1。由于我们要找的数字出现的次数比其他所有数字出现的次数之和还要多，那么要找的数字肯定是最后一次把次数设为1时对应的数字。](SortAndFind/find_more_than_half_number_in_unsorted_array.cpp)
- [最小的 k 个数：输入 n 个整数，找出其中最小的 k 个数。例如，输入 4、5、1、6、2、7、3、8 这 8 个数字，则最小的 4 个数字是 1、2、3、4。解法 1 根据 Partition。解法 2 根据最大堆。](SortAndFind/find_min_kth_in_unsorted_array.cpp)

### 线性阶 O(n) 的线性排序算法

线性排序（Linear sort）。之所以能做到线性的时间复杂度，主要原因是，这三个算法是非基于比较的排序算法，都不涉及元素之间的比较操作。

#### 桶排序（Bucket sort）

首先，我们来看桶排序。桶排序，顾名思义，会用到“桶”，核心思想是将要排序的数据分到几个有序的桶里，每个桶里的数据再单独进行排序。桶内排完序之后，再把每个桶里的数据按照顺序依次取出，组成的序列就是有序的了。

如果要排序的数据有 n 个，我们把它们均匀地划分到 m 个桶内，每个桶里就有 k=n/m 个元素。每个桶内部使用快速排序，时间复杂度为 O(k * logk)。m 个桶排序的时间复杂度就是 O(m * k * logk)，因为 k=n/m，所以整个桶排序的时间复杂度就是 O(n*log(n/m))。当桶的个数 m 接近数据个数 n 时，log(n/m) 就是一个非常小的常量，这个时候桶排序的时间复杂度接近 O(n)。

首先，要排序的数据需要很容易就能划分成 m 个桶，并且，桶与桶之间有着天然的大小顺序。这样每个桶内的数据都排序完之后，桶与桶之间的数据不需要再进行排序。

其次，数据在各个桶之间的分布是比较均匀的。如果数据经过桶的划分之后，有些桶里的数据非常多，有些非常少，很不平均，那桶内数据排序的时间复杂度就不是常量级了。在极端情况下，如果数据都被划分到一个桶里，那就退化为 O(nlogn) 的排序算法了。

桶排序比较适合用在外部排序中。所谓的外部排序就是数据存储在外部磁盘中，数据量比较大，内存有限，无法将数据全部加载到内存中。比如说我们有 10GB 的订单数据，我们希望按订单金额（假设金额都是正整数）进行排序，但是我们的内存有限，只有几百 MB，没办法一次性把 10GB 的数据都加载到内存中。这个时候该怎么办呢？将所有订单根据金额划分到 100 个桶里，那订单会被均匀划分到 100 个文件中，每个小文件中存储大约 100MB 的订单数据，针对这些划分之后还是比较大的文件，我们可以继续划分。

#### 计数排序（Counting sort）

计数排序其实是桶排序的一种特殊情况。当要排序的 n 个数据，所处的范围并不大的时候，比如最大值是 k，我们就可以把数据划分成 k 个桶。每个桶内的数据值都是相同的，省掉了桶内排序的时间。

因为只涉及扫描遍历操作，所以时间复杂度是 O(n)。

计数排序只能用在数据范围不大的场景中，如果数据范围 k 比要排序的数据 n 大很多，就不适合用计数排序了。而且，计数排序只能给非负整数排序，如果要排序的数据是其他类型的，要将其在不改变相对大小的情况下，转化为非负整数。

[从后到前依次扫描未排序数组。比如，当扫描到 3 时，我们可以从统计数组中取出下标为 3 的值 7，也就是说，到目前为止，包括自己在内，分数小于等于 3 的考生有 7 个，也就是说 3 是排序数组中的第 7 个元素（也就是排序数组中下标为 6 的位置）。当 3 放入到排序数组中后，小于等于 3 的元素就只剩下了 6 个了，所以相应的 统计数组[3] 要减 1，变成 6。](SortAndFind/counting_sort.cpp)

#### 基数排序（Radix sort）

假设我们有 10 万个手机号码，希望将这 10 万个手机号码从小到大排序。

先按照最后一位来排序手机号码，然后，再按照倒数第二位重新排序，以此类推，最后按照第一位重新排序。经过 11 次排序之后，手机号码就都有序了。这里按照每位来排序的排序算法要是稳定的。

根据每一位来排序，我们可以用刚讲过的桶排序或者计数排序，它们的时间复杂度可以做到 O(n)。如果要排序的数据有 k 位，那我们就需要 k 次桶排序或者计数排序，总的时间复杂度是 O(k*n)。当 k 不大的时候，比如手机号码排序的例子，k 最大就是 11，所以基数排序的时间复杂度就近似于 O(n)。

有时候要排序的数据并不都是等长的，我们可以把所有的单词补齐到相同长度，位数不够的可以在后面补“0”，因为根据 ASCII 值，所有字母都大于“0”，所以补“0”不会影响到原有的大小顺序。

基数排序对要排序的数据是有要求的，需要可以分割出独立的“位”来比较，而且位之间有递进的关系，如果 a 数据的高位比 b 数据大，那剩下的低位就不用比较了。除此之外，每一位的数据范围不能太大，要可以用线性排序算法来排序，否则，基数排序的时间复杂度就无法做到 O(n) 了。

### stdlib.h 中的 qsort()

qsort() 对于小数据量的排序，会优先使用归并排序来排序输入数据；要排序的数据量比较大的时候，qsort() 会改为用快速排序算法来排序，qsort() 选择分区点的方法就是“三数取中法”，递归太深会导致堆栈溢出的问题，qsort() 是通过自己实现一个堆上的栈，手动模拟递归来解决的；当要排序的区间中，元素的个数小于等于 4 时，qsort() 就退化为插入排序。

## ↔️ 二分查找 Binary Search

二分查找针对的是一个有序的数据集合，查找思想有点类似分治思想。每次都通过跟区间的中间元素对比，将待查找的区间缩小为之前的一半，直到找到要查找的元素，或者区间被缩小为 0。我们假设数据大小是 n，每次查找后数据都会缩小为原来的一半，也就是会除以 2，时间复杂度就是 O(logn)。

### 注意循环退出条件、middle 的取值、low 和 high 的更新

- [有序数组中不存在重复元素的二分查找](SortAndFind/binary_search.cpp)
- [求一个数的平方根，要求精确到小数点后 6 位](SortAndFind/sqrt.cpp)

### 二分查找应用场景的局限性

- 首先，二分查找依赖的是顺序表结构，简单点说就是数组。主要原因是二分查找算法需要按照下标随机访问元素，所以链表是不行的。
- 其次，二分查找针对的是有序数据。二分查找只能用在插入、删除操作不频繁，一次排序多次查找的场景中。
- 再次，数据量太小不适合二分查找。如果要处理的数据量很小，完全没有必要用二分查找，顺序遍历就足够了。
- 最后，数据量太大也不适合二分查找。二分查找的底层需要依赖数组这种数据结构，而数组为了支持随机访问的特性，要求内存空间连续，对内存的要求比较苛刻。

### 二分查找的变形问题，有序数组中有重复元素

- [查找第一个值等于给定值的元素](SortAndFind/binary_search.cpp)，如果 mid 等于 0，那这个元素已经是数组的第一个元素，那它肯定是我们要找的；如果 mid 不等于 0，但 a[mid]的前一个元素 a[mid-1]不等于 value，那也说明 a[mid]就是我们要找的第一个值等于给定值的元素。
- [查找最后一个值等于给定值的元素](SortAndFind/binary_search.cpp)
- [查找第一个大于等于给定值的元素](SortAndFind/binary_search.cpp)
- [查找最后一个小于等于给定值的元素](SortAndFind/binary_search.cpp)
- 定位出一个 IP 地址的归属地：如果 IP 区间与归属地的对应关系不经常更新，我们可以先预处理这 12 万条数据，让其按照起始 IP 从小到大排序。IP 地址可以转化为 32 位的整型数。所以，我们可以将起始地址，按照对应的整型值的大小关系，从小到大进行排序。当我们要查询某个 IP 归属地时，我们可以先通过二分查找，找到最后一个起始 IP 小于等于这个 IP 的 IP 区间，然后，检查这个 IP 是否在这个 IP 区间内，如果在，我们就取出对应的归属地显示；如果不在，就返回未查找到。

### 有序数组的旋转

- 把一个数组最开始的若干个元素搬到数组的末尾，称之为数组的旋转，例如，数组 {3, 4, 5, 1, 2} 为 {1, 2, 3, 4, 5} 的一个旋转。
- [输入一个递增排序的数组的一个旋转，输出旋转数组的最小元素，如果当前查找的范围存在重复值，就需要退化为顺序查找。](SortAndFind/rotated_array.cpp)
- [在一个递增排序的数组的一个旋转中查找指定值。](SortAndFind/rotated_array.cpp)

### 数组是排序就应该想到使用二分查找

- [统计一个数字在排序数组中出现的次数，转换为查找第一个值等于给定值的元素和查找最后一个值等于给定值的元素，根据下标算次数。](SortAndFind/binary_search2.cpp)
- [一个长度为 n - 1 的递增排序数组中的所有数字都是唯一的，并且每个数字都在范围 0~n-1 之内。在范围 0~n-1 内的 n 个数字中有且只有一个数字不在该数组中，找出这个数字，转换为查找数组中第一个数值和下标不相等的元素。](SortAndFind/binary_search2.cpp)
- [在一个单调递增的数组里每个元素都是整数并且是唯一的，找出数组中任意一个数值等于其下标的元素](SortAndFind/binary_search2.cpp)

## ⛓ 跳表 Skip List

跳表使用空间换时间的设计思路，通过构建多级索引来提高查询的效率，实现了基于链表的“二分查找”。跳表是一种动态数据结构，支持快速地插入、删除、查找操作，时间复杂度都是 O(logn)。跳表的空间复杂度是 O(n)。不过，跳表的实现非常灵活，可以通过改变索引构建策略，有效平衡执行效率和内存消耗。

## 🗂 散列表 Hash Table

散列表用的是数组支持按照下标随机访问数据的特性，所以散列表其实就是数组的一种扩展，由数组演化而来。可以说，如果没有数组，就没有散列表。

假如我们有 89 名选手参加学校运动会，编号用 6 位数字来表示。比如 051167，其中，前两位 05 表示年级，中间两位 11 表示班级，最后两位还是原来的编号 1 到 89。其中，参赛选手的编号我们叫做键（key）或者关键字。我们用它来标识一个选手。我们把参赛编号转化为数组下标的映射方法就叫作散列函数（或“Hash 函数”“哈希函数”），而散列函数计算得到的值就叫作散列值（或“Hash 值”“哈希值”）。

### 散列函数

hash(key)，其中 key 表示元素的键值，hash(key) 的值表示经过散列函数计算得到的散列值。

散列函数设计的基本要求：

- 散列函数计算得到的散列值是一个非负整数；
- 如果 key1 == key2，那 hash(key1) == hash(key2)；
- 如果 key1 ≠ key2，那 hash(key1) ≠ hash(key2)。真实的情况下，要想找到一个不同的 key 对应的散列值都不一样的散列函数，几乎是不可能的，无法完全避免这种散列冲突。

要尽可能让散列后的值随机且均匀分布，这样会尽可能地减少散列冲突，即便冲突之后，分配到每个槽内的数据也比较均匀。除此之外，散列函数的设计也不能太复杂，太复杂就会太耗时间，也会影响散列表的性能。

### 装载因子和动态扩容

不管采用哪种探测方法，当散列表中空闲位置不多的时候，散列冲突的概率就会大大提高。用装载因子（load factor）来表示空位的多少：

    散列表的装载因子 = 填入表中的元素个数 / 散列表的长度
    
针对散列表，当装载因子过大时，我们也可以进行动态扩容，重新申请一个更大的散列表，将数据搬移到这个新散列表中，通过散列函数重新计算每个数据的存储位置。为了解决一次性扩容耗时过多的情况，我们可以将扩容操作穿插在插入操作的过程中，分批完成。当装载因子触达阈值之后，我们只申请新空间，但并不将老的数据搬移到新散列表中。当有新数据要插入时，我们将新数据插入新散列表中，并且从老的散列表中拿出一个数据放入到新散列表。每次插入一个数据到散列表，我们都重复上面的过程。经过多次插入操作之后，老的散列表中的数据就一点一点全部搬移到新散列表中了。这样没有了集中的一次性数据搬移，插入操作就都变得很快了。

### 散列冲突

大部分情况下，链表法更加普适。基于链表的散列冲突处理方法比较适合存储大对象、大数据量的散列表，也就是链表的优缺点，而且，比起开放寻址法，它更加灵活，支持更多的优化策略，比如用跳表、红黑树代替链表，来避免散列表时间复杂度退化成 O(n)，抵御散列碰撞攻击。但是，对于小规模数据、装载因子不高的散列表，比较适合用开放寻址法，也就是数组的优缺点。

#### 开放寻址法

开放寻址法的核心思想是，如果出现了散列冲突，我们就重新探测一个空闲位置，将其插入。

重新探测新的位置：

- 线性探测（Linear Probing），往散列表中插入数据时，如果某个数据经过散列函数散列之后，存储位置已经被占用了，我们就从当前位置开始，依次往后查找，看是否有空闲位置，直到找到为止。
- 二次探测（Quadratic Probing），所谓二次探测，跟线性探测很像，线性探测每次探测的步长是 1，而二次探测探测的步长就变成了原来的“二次方”。
- 双重散列（Double hashing），意思就是不仅要使用一个散列函数。我们使用一组散列函数 hash1(key)，hash2(key)，hash3(key)……我们先用第一个散列函数，如果计算得到的存储位置已经被占用，再用第二个散列函数，依次类推，直到找到空闲的存储位置。

#### 链表法

在散列表中，每个“桶（bucket）”或者“槽（slot）”会对应一条链表，所有散列值相同的元素我们都放到相同槽位对应的链表中。

### 散列表和链表常一起使用

- Word 文档中单词拼写检查功能是如何实现的：用的英文单词有 20 万个左右，假设单词的平均长度是 10 个字母，平均一个单词占用 10 个字节的内存空间，那 20 万英文单词大约占 2MB 的存储空间，就算放大 10 倍也就是 20MB。对于现在的计算机来说，这个大小完全可以放在内存里面。所以我们可以用散列表来存储整个英文单词词典。当用户输入某个英文单词时，我们拿用户输入的单词去散列表中查找。如果查到，则说明拼写正确；如果没有查到，则说明拼写可能有误，给予提示。借助散列表这种数据结构，我们就可以轻松实现快速判断是否存在拼写错误。
- 假设我们有 10 万条 URL 访问日志，如何按照访问次数给 URL 排序：遍历 10 万条数据，以 URL 为 key，访问次数为 value，存入散列表，同时记录下访问次数的最大值 K，时间复杂度 O(N)。如果 K 不是很大，可以使用桶排序，时间复杂度 O(N)。如果 K 非常大（比如大于 10 万），就使用快速排序，复杂度 O(NlogN)。
- 有两个字符串数组，每个数组大约有 10 万条字符串，如何快速找出两个数组中相同的字符串：以第一个字符串数组构建散列表，key 为字符串，value 为出现次数。再遍历第二个字符串数组，以字符串为 key 在散列表中查找，如果 value 大于零，说明存在相同字符串。时间复杂度 O(N)。
- LRU 缓存淘汰算法：使用散列表和双向链表，双向链表按最近访问时间排序，双向链表有头指针和尾指针，节点中包含数据、双向链表中的前驱指针、双向链表中的后继指针、散列表拉链中的后继指针；因为有了散列表，所以访问数据时，时间复杂度都是 O(1)；访问数据时，已经缓存的数据，移动到链表头部；没有缓存的数据，缓存未满，新数据直接插入到链表的头部；缓存已经满，则删除链表尾节点，新数据再插入到链表的头部。
- 假设猎聘网有 10 万名猎头，每个猎头都可以通过做任务（比如发布职位）来积累积分，然后通过积分来下载简历。假设你是猎聘网的一名工程师，如何在内存中存储这 10 万个猎头 ID 和积分信息，让它能够支持这样几个操作：根据猎头的 ID 快速查找、删除、更新这个猎头的积分信息（根据 ID 来构建散列表）；查找积分在某个区间的猎头 ID 列表（根据积分来构建跳表，通过跳表的二分查找，找到区间起始位置）；查找按照积分从小到大排名在第 x 位到第 y 位之间的猎头 ID 列表。（通过跳表的二分查找，找到区间起始位置）。

### 基于数组的散列表

- 如果需要判断多个字符是不是在某个字符串里出现过或者统计多个字符在某个字符串中出现的次数，那么我们可以考虑基于数组创建一个简单的散列表，这样可以用很小的空间消耗换来时间效率的提升。
- [在字符串中找出第一个只出现一次的字符，如输入"abaccdeff"，则输出'b'。](HashTable/char_hash_table.cpp)
- 定义一个函数，输入两个字符串，从第一个字符串中删除在第二个字符串中出现过的所有字符。例如，从第一个字符串"We are students."中删除在第二个字符串"aeiou"中出现过的字符得到的结果是"W r Stdnts."。为了解决这个问题，我们可以创建一个用数组实现的简单哈希表来存储第二个字符串。这样我们从头到尾扫描第一个字符串的每个字符时，用 O(1) 时间就能判断出该字符是不是在第一个字符串中。如果第一个字符串的长度是 n，那么总的时间复杂度是 O(n)。
- 定义一个函数，删除字符串中所有重复出现的字符。例如，输入"google"，删除重复的字符之后的结果是"gole"。这道题目和上面的问题比较类似，我们可以创建一个用布尔型数组实现的简单的哈希表。数组中的元素的意义是其下标看作 ASCII 码后对应的字母在字符串中是否已经出现。我们先把数组中所有的元素都设为 false。以"google"为例，当扫描到第一个 g 时，g 的 ASCII 码是 103，那我们把数组中下标为 103 的元素设为 true。当扫描到第二个 g 时，我们发现数组中下标为 103 的元素的值是 true，就知道 g 在前面已经出现过。也就是说，我们用 O(1) 时间就能判断出每个字符是否在前面已经出现过。如果字符串的长度是 n，那么总的时间复杂是 O(n)。
- 在英语中，如果两个单词中出现的字母相同，并且每个字母出现的次数也相同，那么这两个单词互为变位词。例如，silent 与 listen、evil 与 live 等互为变位词。请完成一个函数，判断输入两个字符串是不是互为变位词。我们可以创建一个用数组实现的简单哈希表，用来统计字符串中每个字符出现的次数。当扫描到第一个字符串中的每个字符时，为哈希表对应的项的值增加 1。接下来扫描第二个字符串，当扫描到每个字符时，为哈希表对应的项的减去 1。如果扫描完第二个字符串后，哈希表中所有的值都是 0，那么这两个字符串就互为变位词。
- [实现一个函数，用来找出字符串流中第一个只出现一次的字符，例如，当从字符流中只读出前两个字符"go"时，第一个只出现一次的字符是'g'；当从该字符流中读出前六个字符"google"时，第一个只出现一次的字符是'l'](HashTable/char_hash_table.cpp)

## 🔑 哈希 Hash

将任意长度的二进制值串映射为固定长度的二进制值串，这个映射的规则就是哈希算法，而通过原始数据映射之后得到的二进制值串就是哈希值。

需要满足的几点要求：

- 从哈希值不能反向推导出原始数据（所以哈希算法也叫单向哈希算法）；
- 对输入数据非常敏感，哪怕原始数据只修改了一个 Bit，最后得到的哈希值也大不相同；
- 散列冲突的概率要很小，对于不同的原始数据，哈希值相同的概率非常小；
- 哈希算法的执行效率要尽量高效，针对较长的文本，也能快速地计算出哈希值。

应用：

- 安全加密：加密的目的就是防止原始数据泄露，所以很难通过哈希值反向推导原始数据，这是一个最基本的要求。MD5 哈希值是固定的 128 位二进制串，能表示的数据是有限的，最多能表示 2^128 个数据，这个数据已经是一个天文数字了，所以散列冲突的概率要小于 1/2^128。
- 唯一标识：哈希算法可以对大数据做信息摘要，通过一个较短的二进制编码来表示很大的数据。每一个图片取一个唯一标识，或者说信息摘要。比如，我们可以从图片的二进制码串开头取 100 个字节，从中间取 100 个字节，从最后再取 100 个字节，然后将这 300 个字节放到一块，通过哈希算法（比如 MD5），得到一个哈希字符串，用它作为图片的唯一标识。
- 数据校验：从多个机器上并行下载一个 2GB 的电影，这个电影文件可能会被分割成很多文件块（比如可以分成 100 块，每块大约 20MB）。等所有的文件块都下载完成之后，再组装成一个完整的电影文件就行了。通过哈希算法，对 100 个文件块分别取哈希值，并且保存在种子文件中。当文件块下载完成之后，我们可以通过相同的哈希算法，对下载好的文件块逐一求哈希值，然后跟种子文件中保存的哈希值比对。如果不同，说明这个文件块不完整或者被篡改了，需要再重新从其他宿主机器上下载这个文件块。
- 散列函数：散列表对哈希算法的要求非常特别，更加看重的是散列的平均性和哈希算法的执行效率。
- 负载均衡：我们可以通过哈希算法，对客户端 IP 地址或者会话 ID 计算哈希值，将取得的哈希值与服务器列表的大小进行取模运算，最终得到的值就是应该被路由到的服务器编号。
- 数据分片
    - 假如我们有 1T 的日志文件，这里面记录了用户的搜索关键词，我们想要快速统计出每个关键词被搜索的次数，先把日志文件分成 n 份，同时在 n 个机器上，分别从搜索记录的日志文件中，依次读出每个搜索关键词，并且通过哈希函数计算哈希值，然后再跟 n 取模，最终得到的值，就是应该被分配到的机器编号。这样，哈希值相同的搜索关键词就被分配到了同一个机器上。每个机器会分别计算关键词出现的次数，最后合并起来就是最终的结果。
    - 假设现在我们的图库中有 1 亿张图片，我们准备 n 台机器，让每台机器只维护某一部分图片对应的散列表。我们每次从图库中读取一个图片，计算唯一标识，然后与机器个数 n 求余取模，得到的值就对应要分配的机器编号，然后将这个图片的唯一标识和图片路径发往对应的机器构建散列表。当我们要判断一个图片是否在图库中的时候，我们通过同样的哈希算法，计算这个图片的唯一标识，然后与机器个数 n 求余取模。假设得到的值是 k，那就去编号 k 的机器构建的散列表中查找。
- 分布式存储：通过哈希算法对数据取哈希值，然后对机器个数取模，这个最终值就是应该存储的缓存机器编号。

## 🌲 二叉树 Binary Tree

### 树

节点的高度 = 节点到叶子节点的最长路径
节点的深度 = 根节点到这个节点所经历的边的个数
节点的层数 = 节点的深度 + 1

树的高度 = 树的深度 = 根节点的高度
树的路径：从根节点开始往下一直到叶节点所经过的节点形成一条路径

### 二叉树

在二叉树中每个节点最多只能有两个节点。有链式存储法和顺序存储法。

- 给定一组数据，比如 1，3，5，6，9，10。你来算算，可以构建出多少种不同的二叉树？如果是完全二叉树，可以放在数组里面，简化为数组内的元素有多少种组合方式，这样的话，就是 n!

### 满二叉树

叶子节点全都在最底层，除了叶子节点之外，每个节点都有左右两个子节点，这种二叉树就叫做满二叉树。

### 完全二叉树

叶子节点都在最底下两层，最后一层的叶子节点都靠左排列，并且除了最后一层，其他层的节点个数都要达到最大，这种二叉树叫做完全二叉树。适合于顺序存储法。

### 二叉搜索树 Binary Search Tree (BST)

左子节点总是小于或等于根节点，而右子节点总是大于或等于根节点，平均在 O(logn) 的时间内根据数值在 BST 中找到一个节点。

- [二叉搜索树的查找](BinaryTree/binary_search_tree.cpp)，如果要查找的数据比根节点的值小，那就在左子树中递归查找；如果要查找的数据比根节点的值大，那就在右子树中递归查找。
- [二叉搜索树的查找最小节点](BinaryTree/binary_search_tree.cpp)，左子树中递归查找。
- [二叉搜索树的查找最大节点](BinaryTree/binary_search_tree.cpp)，右子树中递归查找。
- [二叉搜索树的插入](BinaryTree/binary_search_tree.cpp)，如果要插入的数据比节点的数据大，并且节点的右子树为空，就将新数据直接插到右子节点的位置；如果不为空，就再递归遍历右子树，查找插入位置。同理，如果要插入的数据比节点数值小，并且节点的左子树为空，就将新数据插入到左子节点的位置；如果不为空，就再递归遍历左子树，查找插入位置。
- [二叉搜索树的删除](BinaryTree/binary_search_tree.cpp)
    - 第一种情况是，如果要删除的节点没有子节点，只需要直接将父节点中，指向要删除节点的指针置为 null
    - 第二种情况是，如果要删除的节点只有一个子节点（只有左子节点或者右子节点），只需要更新父节点中，指向要删除节点的指针，让它指向要删除节点的子节点就可以了。
    - 第三种情况是，如果要删除的节点有两个子节点。需要找到这个节点的右子树中的最小节点，把它替换到要删除的节点上。然后再删除掉这个最小节点，因为最小节点肯定没有左子节点（如果有左子结点，那就不是最小节点了），所以，可以应用上面两条规则来删除这个最小节点。
- [二叉搜索树的前驱节点](BinaryTree/binary_search_tree.cpp)
    - 第一种情况，有左子树，左子树的最大节点就是前驱节点。
    - 第二种情况，无左子树，是父节点的右子节点，父节点就是前驱节点。
    - 第三种情况，无左子树，是父节点的左子节点，如果父节点有父节点且父节点是父父节点的左子节点，就一直往上走找一个祖先节点，其最低左子节点就是目标节点，祖先节点的父节点就是前驱节点。
- [二叉搜索树的后继节点](BinaryTree/binary_search_tree.cpp)
    - 第一种情况，有右子树，右子树的最小节点就是后继节点。
    - 第二种情况，无右子树，是父节点的左子节点，父节点就是后继节点。
    - 第三种情况，无右子树，是父节点的右子节点，如果父节点有父节点且父节点是父父节点的右子节点，就一直往上走找一个祖先节点，其最低右子节点就是目标节点，祖先节点的父节点就是后继节点。
- 时间复杂度分析：查找、插入、删除等很多操作的时间复杂度都跟树的高度成正比。两个极端情况的时间复杂度分别是 O(n) 和 O(logn)，分别对应二叉树退化成链表的情况和完全二叉树。
- 支持重复数据的二叉搜索树：第一种方法，二叉查找树中每一个节点不仅会存储一个数据，因此我们通过链表和支持动态扩容的数组等数据结构，把值相同的数据都存储在同一个节点上。第二种方法，每个节点仍然只存储一个数据，在查找插入位置的过程中，如果碰到一个节点的值，与要插入数据的值相同，我们就将这个要插入的数据放到这个节点的右子树，也就是说，把这个新插入的数据当作大于这个节点的值来处理。
- 散列表和二叉搜索树的比较
    - 第一，散列表中的数据是无序存储的，如果要输出有序的数据，需要先进行排序。而对于二叉查找树来说，我们只需要中序遍历，就可以在 O(n) 的时间复杂度内，输出有序的数据序列。
    - 第二，散列表扩容耗时很多，而且当遇到散列冲突时，性能不稳定，尽管二叉查找树的性能不稳定，但是在工程中，我们最常用的平衡二叉查找树的性能非常稳定，时间复杂度稳定在 O(logn)。
    - 第三，笼统地来说，尽管散列表的查找等操作的时间复杂度是常量级的，但因为哈希冲突的存在，这个常量不一定比 logn 小，所以实际的查找速度可能不一定比 O(logn) 快。加上哈希函数的耗时，也不一定就比平衡二叉查找树的效率高。
    - 第四，散列表的构造比二叉查找树要复杂，需要考虑的东西很多。比如散列函数的设计、冲突解决办法、扩容、缩容等。平衡二叉查找树只需要考虑平衡性这一个问题，而且这个问题的解决方案比较成熟、固定。
    - 最后，为了避免过多的散列冲突，散列表装载因子不能太大，特别是基于开放寻址法解决冲突的散列表，不然会浪费一定的存储空间。

### 平衡二叉树

严格定义：二叉树中任意一个节点的左右子树的高度相差不能大于 1。从这个定义来看，上一节我们讲的完全二叉树、满二叉树其实都是平衡二叉树，但是非完全二叉树也有可能是平衡二叉树。

不严格定义：平衡二叉查找树中“平衡”的意思，其实就是让整棵树左右看起来比较“对称”、比较“平衡”，不要出现左子树很高、右子树很矮的情况。这样就能让整棵树的高度相对来说低一些，相应的插入、删除、查找等操作的效率高一些。
 
### 红黑树 Red-Black Tree

红黑树是一种平衡二叉查找树。它是为了解决普通二叉查找树在数据更新的过程中，复杂度退化的问题而产生的。红黑树的高度近似 log2n，所以它是近似平衡，插入、删除、查找操作的时间复杂度都是 O(logn)。

一棵红黑树需要满足这样几个要求：

1. 红黑树中的节点，一类被标记为黑色，一类被标记为红色；
2. 根节点是黑色的；
3. 每个叶子节点都是黑色的空节点（NIL），也就是说，叶子节点不存储数据；
4. 任何相邻的节点都不能同时为红色，也就是说，红色节点是被黑色节点隔开的；
5. 每个节点，从该节点到达其可达叶子节点的所有路径，都包含相同数目的黑色节点；

在插入、删除节点的过程中，第 4 点、第 5点要求可能会被破坏，通过左旋和右旋等基本操作来恢复。

### 测试用例

- [完全二叉树](Google_tests/BinaryTree/CompleteBinaryTreeTest.cpp)，[完全二叉搜索树](Google_tests/BinaryTree/CompleteBSTTest.cpp)
- [非完全二叉树](Google_tests/BinaryTree/NonCompleteBinaryTreeTest.cpp)，[非完全二叉搜索树](Google_tests/BinaryTree/NonCompleteBSTTest.cpp)
- [只有左节点的二叉树](Google_tests/BinaryTree/OnlyLeftNodeBinaryTreeTest.cpp)，[只有左节点的二叉搜索树](Google_tests/BinaryTree/OnlyLeftNodeBSTTest.cpp)
- [只有右节点的二叉树](Google_tests/BinaryTree/OnlyRightNodeBinaryTreeTest.cpp)，[只有右节点的二叉搜索树](Google_tests/BinaryTree/OnlyRightNodeBSTTest.cpp)
- [只有一个节点的二叉树](Google_tests/BinaryTree/OneNodeBinaryTreeTest.cpp)
- [空的二叉树](Google_tests/BinaryTree/EmptyBinaryTreeTest.cpp)

### 三种基本遍历

掌握前序遍历、中序遍历、后序遍历，命名的方式是操作子树根节点相对于遍历其左右子树的顺序。二叉树遍历的时间复杂度是 O(n)。

- [前序遍历](BinaryTree/binary_tree.cpp)
- [中序遍历](BinaryTree/binary_tree.cpp)
- [后序遍历](BinaryTree/binary_tree.cpp)

### 前序遍历结果的特点

第一个数字是树的根节点的值，后面的数字可以分为两部分，第一部分是左子树节点的值，如果是 BST，它们都比根节点的值小，
第一部分是右子树节点的值，如果是 BST，它们都比根节点的值大。

- [输入二叉树的前序遍历和中序遍历的结果，结果中不含重复数字，重建此二叉树](BinaryTree/construct_binary_tree_with_preorder_inorder_walk_result.cpp)
- [输入两棵二叉树 A 和 B，判断 B 是不是 A 的子结构](BinaryTree/binary_tree_contain_sub_tree.cpp)
- [二叉树的镜像](BinaryTree/mirror_binary_tree.cpp)
- [对称的二叉树](BinaryTree/binary_tree_is_symmetrical.cpp)
- [序列化和反序列化二叉树](BinaryTree/serialize_binary_tree.cpp)

### 中序遍历结果的特点

根节点的值在中间，剩下的数字可以分为前后两部分，前面部分是左子树节点的值，如果是 BST，它们都比根节点的值小，后面部分是右子树节点的值，如果是 BST，它们都比根节点的值大。

- [查找二叉搜索树的第 k 大节点](BinaryTree/find_kth_node_in_bst.cpp)
- [输入一个棵二叉搜索树，将其转换成一个排序的双向链表，不能创建任何新的节点，只能调整树中节点指针的指向](BinaryTree/bst_to_link_list.cpp)
- [找出二叉树中一个节点的中序遍历序列的下一个节点，树中的节点还有一个指向父节点的指针](BinaryTree/get_binary_tree_inorder_walk_next.cpp)

### 后序遍历结果的特点

最后一个数字是数的根节点的值，前面的数字可以分为两部分，第一部分是左子树节点的值，如果是 BST，它们都比根节点的值小，
第一部分是右子树节点的值，如果是 BST，它们都比根节点的值大。

- [输入一个整数数组，判断该数组是不是某二叉搜索树的后序遍历结果](BinaryTree/is_postorder_sequence_of_bst.cpp)
- [二叉树的深度](BinaryTree/binary_tree_depth.cpp)
- [平衡二叉树，任意节点的左、右子树的深度相差不超过 1](BinaryTree/binary_tree_is_balance.cpp)

### 利用队列或栈作为树的辅助

- [从上到下打印二叉树](BinaryTree/top_to_bottom_binary_tree_walk.cpp)
- [分行从上到下打印二叉树](BinaryTree/top_to_bottom_binary_tree_walk.cpp)
- [之字形从上到下打印二叉树](BinaryTree/top_to_bottom_binary_tree_walk.cpp)
- [输入一颗二叉树和一个整数，打印出二叉树中节点值的和为输入整数的所有路径](BinaryTree/find_summary_path_in_binary_tree.cpp)

### 树中两个节点的最低公共祖先

- 二叉搜索树：从树的根节点开始和两个输入的节点进行比较，如果当前节点的值比两个节点的值都大，那么最低的共同父节点一定在当前节点的左子树中，于是下一步遍历当前节点的左子节点，如果当前节点的值比两个节点的值都小，那么最低的共同父节点一定在当前节点的右子树中，于是下一步遍历当前节点的右子节点，这样，在树中从上到下找到的第一个在两个输入节点的值之间的节点就是最低的公共祖先。
- 节点带有父节点的树：从树的每个叶节点开始都有一个由指针 parent 串起来的链表，这些链表的尾指针都是树的根节点，两个节点位于两个链表上，它们的最低公共祖先刚好就是这两个链表的一个公共节点。
- [普通树：用两个链表分别保存从根节点到输入的两个节点的路径，把问题转换成两个链表的最后公共节点。](Tree/get_tree_last_common_parent.cpp)

## 🔤 字符串

- [字符串转数字: 10 进制，如 "1234" => 1234](String/string_to_int.cpp)
- [字符串转数字: 26 进制的大写字母，如 A=1,B=2,C=3,...,Z=26,AA=27,AB=28](String/string_to_int.cpp)
- [输入一个英文句子，翻转句子中单词的顺序，但单词内字符的顺序不变。为简单起见，标点符号和普通字母一样处理。例如输入字符串 "I am a student."，则输出 "student. a am I"。](String/reverse_string.cpp)
- [字符串的左旋转操作是把字符串前面的若干个字符转移到字符串的尾部，比如，输入字符串 "abcdefg" 和数字 2，该函数将返回左旋转两位得到的结果 "cdefgab"。](String/reverse_string.cpp)

### 大数问题，用字符串表示数字

- [打印从 1 到最大的 n 位数：输入数字 n，按顺序打印出从 1 到最大的 n 位十进制数，比如输入 3，则打印出 1、2、3 一直到最大的 3 位数 999。](String/print_one_to_max_of_n_digits.cpp)
- [表示数值的字符串：实现一个函数用来判断字符串是否表示数值（包括整数和小数）。例如，字符串 "+100"、"5e2"、"-123"、"3.1416" 及 "-1E-16" 都表示数值，但 "12e"、"1a3.14"、"1.2.3"、"+-5" 及 "12e+5.4" 都不是。表示数值的字符串遵循模式 A\[.\[B\]\]\[e|EC\] 或者.B\[e|EC\]，其中 A 为数值的整数部分，B 紧跟着小数点为数值的小数部分，C 紧跟着 'e' 或者 'E' 为数值的指数部分。在小数里可能没有数值的整数部分。例如，小数 .123 等于 0.123。因此 A 部分不是必需的。如果一个数没有整数部分，那么它的小数部分不能为空。上述 A 和 C 都是可能以 '+' 或者 '-' 开头的 0～9 的数位串；B 也是 0～9 的数位串，但前面不能有正负号。](String/is_string_represent_number.cpp
)

## 0️⃣ 位运算 Bitwise Operation

| Operator | Symbol | Form | Operation |
| ---- | ---- | ---- | ---- |
| left shift | << | x << y | all bits in x shifted left y bits |
| right shift | >> | x >> y | all bits in x shifted right y bits |
| bitwise NOT | ~ | ~x | all bits in x flipped |
| bitwise AND | & | x & y | each bit in x AND each bit in y |
| bitwise OR | &#124; | x &#124; y | each bit in x OR each bit in y |
| bitwise XOR | ^ | x ^ y | each bit in x XOR each bit in y |

异或：

    0 ^ 0 = 0
    1 ^ 0 = 1
    0 ^ 1 = 1
    1 ^ 1 = 0

左移运算符 m << n 把 m 左移 n 位，最左边的 n 位被丢弃，同时在最右边补上 n 个 0：

    00001010 << 2 = 00101000
    10001010 << 3 = 01010000

右移运算符 m >> n 把 m 右移 n 位，最右边的 n 位被丢弃。如果数字是一个无符号数值，则用 0 填补最左边的 n 位；如果数字是一个有符号数值，则用数字的符号位填补最左边的 n 位，也就是如果数字原先是正数，则填补 0，如果数字原先是负数，则填补 1：

    00001010 >> 2 = 00000010
    10001010 >> 3 = 11110001

### 理解位运算的特点

- 避免使用右移可能导致的死循环。
- 重要的技巧，把一个整数减去 1 之后再和原来的整数做位与运算，得到的结果相当于把整数的二进制表示中最右边的 1 变成 0。
- [输入一个整数，输出该数二进制表示中 1 的个数。](Bitwise/count_one_of_number.cpp)
- [一个整型数组里除两个数字之外，其他数字都出现了两次，找出这两个数字，要求时间复杂度是 O(n)，空间复杂度是 O(1)，成对出现的数字在异或中全部抵消了，两个数字不同，异或的结果不为 0，结果数字的二进制表示中至少有一位为 1，在结果数字中找第一个为 1 的位的位置，记为第 n 位，以第 n 位是不是 1 把原数组中的数字分成两个子数组，分别找出只出现一次的数字。](Bitwise/find_numbers_appear_once.cpp)
- [一个整型数组中除一个数字只出现一次之外，其他数字都出现了三次，找出这个数字，把数组中所有数字的二进制表示的每一位都加起来，如果某一位的和能被 3 整除，那么那个只出现一次的数字二进制表示中对应的那一位是 0，否则就是 1。](Bitwise/find_numbers_appear_once.cpp)
- [不用加减乘除做加法，求两个整数之和，分三步走，第一步，不考虑进位对每一位相加，0 加 0、1 加 1 的结果都是 0，0 加 1、1 加 0 的结果都是 1，这和异或的结果是一样的；第二步，考虑进位，对 0 加 0、0 加 1、1 加 0，都不会产生进位，只有 1 加 1，会向前产生一个进位，这就是两个数先做位与运算，再向左移动一位；第三步，把前两个步骤的结果相加，依然是重复前两步，直到不产生进位为止。](Bitwise/add_with_bitwise.cpp)
- 不使用新的变量，交换两个变量的值，`a = a ^ b; b = a ^ b; a = a ^ b`。

## 🧮 其他

- [数值的整数次方：实现函数 double Power(double base, int exponent)，求 base 的 exponent 次方，不得使用库函数，不需要考虑大数问题。](Other/power.cpp)

用空间换时间的设计思想。当内存空间充足的时候，如果我们更加追求代码的执行速度，我们就可以选择空间复杂度相对较高、但时间复杂度相对很低的算法或者数据结构。相反，如果内存比较紧缺，比如代码跑在手机或者单片机上，这个时候，就要反过来用时间换空间的设计思路。

- [整数数组中查找最长递增序列](time_efficiency.cpp#L13)
